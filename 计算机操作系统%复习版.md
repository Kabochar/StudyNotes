# 计算机操作系统 - 自我提问

[TOC]

# 进程 与 线程 *

## 1，进程

进程：资源分配的基本单位。

进程控制块：描述 进程的基本信息 和 运行状态。创建进程 和 撤销进程 都是针对 PCB （进程控制块）进行操作。

## 2，线程

线程：独立调度的基本单位。

一个进程可以有多个线程，他们之间共享进程资源。

## 3，进程 VS 线程

### Ⅰ，所拥有的资源

线程 是 资源分配的基本单位，但 线程 不配有 资源，线程 可以访问 隶属进程的资源。

### Ⅱ，调度

线程 是 独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换。从一个进程中的线程 切换到 另一个进程的进程时，才会引起进程切换。

### Ⅲ，系统开销

进程的创建和撤销，系统都要为之 分配 或 回收资源，如 内容空间，I/O 设备等，所付出的开销远远大于 创建 或  撤销线程时的开销。

进行进程切换时，涉及当前执行 进程 CPU 环境的保存及 新调度 CPU 环境的配置 ； 线程切换时，只需要 保存 和 设置 少量寄存器内容，开销很小。

### Ⅳ，通信方面

线程间可以通过直接读写同一进程中的数据 进行通信，但是进行通信需要借助 IPC。

# 进程状态的切换 ***

-   就绪状态：等待被调度
-   运行状态：
-   堵塞状态

注意事项：

1，只有 就绪状态 与  运行状态 可以相互转换，其他都是都是单向转换。就绪状态的进程通过 调度算法 从而获得 CPU 时间片，转为运行状态；而 运行状态 的进程，在 分配给它的 CPU时间片 用完之后 就会转为 就绪状态，等待下一次被调度。

2，堵塞状态 是 缺少需要的资源，从而由运行状态转换而来，但是该资源不包括 CPU 时间。缺少 CPU 时间会从 运行状态 转换为 就绪状态。

# 进程调度算法 *

不同环境的调度算法不同，因此需要针对不同环境来讨论。

## 1，批处理系统

批处理系统没有太多的用户操作。在该系统中，调度算法目标：保证吞吐量，周转时间（从提交到终止的时间）。

### 1.1，先来先服务 first-come first-served（FCFS）

原则：按照 请求的顺序 进行调度

有利于长作业，不利于短作业。

原因：因为短作业一直等待前面的长作业执行完毕才能执行，而长作业又需要很长时间，造成了短作业等地啊时间过长。

### 1.2，短作业优先 shortest job first（SJF）

原则：按 估计时间最短的顺序 进行调度。

长作业有可能饿死，处于一直等待短作业完毕的状态。

因为：如果短作业到来，那么长作业远远得不到调度。

### 1.3，最短剩余时间优先 shortest remaining time next（SRTN）

按 估计剩余时间最短的顺序 进行调度。

## 2，交互式系统

交互式系统由大量的用户交互操作，在该系统中调度算法的目标：快速地进行响应。

### 2.1，时间片轮转

将 所有就绪进程 按 FCFS 的原则排成一个队列，每次调度时，把 CPU时间分配给 队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮状算法的 效率 和 时间片的大小 有很大关系：

-   因为进程切换要 保存进程的信息 并且 载入新进程的信息，如果时间片太小，会导致进程切换太频繁，使得进程切换上就会花过多时间。

-   而  如果时间片过长，实时性得不到保证。

### 2.2，优先级调度

操作：为每个进程分配一个优先级，按 优先级 调度。

可以 随着时间的推移等待进程的优先级，防止优先级低的进程远远得不到重用。

### 2.3，多级反馈队列

背景：一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级反馈队列 - 出现原因：为 需要连续执行多个时间片的进程。

实现：多级反馈队列设置了多个队列，每个队列时间片大小都不同，例如：1，2，4，5... 。进程在第一个没执行完，就会被移动到下一个队列。这种方式操作下， 之前的进程只需要操作 7次。每个队列优先权不同，最上面的优先权最高。因此 只有上一个队列没有进程在排队，才能调度当前队列上的进程。

这种调度算法 可以看成 是 时间片轮状调度算法 和 有优先级调度算法 的结合。

## 3，实时系统

实时系统 要求：一个请求在一个确定时间内得到响应。

分为 硬实时 和 软实时。硬实时：必要满足绝对的截至时间。软实时：可以容忍一定的超时。

# 线程的实现方式 ***

图片来源：@[James](https://www.jianshu.com/u/2f94d767ef4e)  ---  https://www.jianshu.com/p/2066fd67ed67

参考文章：https://www.jianshu.com/p/2066fd67ed67

## 线程的几种实现方式

1，用户级线程（User-LevelThread, ULT）：由 应用程序所支持 的线程实现，内核 意识 不到用户级线程的实现

2，内核级（Kemel-LevelThread, KLT）：内核级 又称为 内核支持的线程。

3，组合级线程：线程创建完全在用户空间中完成，线程的调度 和 同步也在应用程序中进行。

一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级的数目）内核级线程中。

## 用户线程

### 优点：

1，可以在不支持线程的操作系统中实现。

2，创建 和 销毁线程，线程切换代价等线程管理代价比内核线程少，因为保存线程状态的过程和调用程序只是本地过程。

3，允许每个进程定制自己的调度算法，线程管理比较灵活。

4，线程能够利用的 表空间 和 堆栈空间 比内核级线程多。

5，不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，使得线程调用非常快捷。

6，线程的调度不需要内核直接参与，控制简单。

### 缺点：

1，线程发生 I/O 或 页面故障 引起的堵塞时，如果调用堵塞系统调用则内核由于不知道有多线程的存在，而会堵塞整个进程从而堵塞所有线程，因此，同一进程中只能有一个线程在运行。

2，页面失效也会产生类似的问题

3，一个单独的进程内部，没有时钟中断，所以，不可能 用轮转调度的方式调度线程。

4，资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用

## 内核线程

### 优点：

1，多处理器系统中，内核能够 并行执行 同一进程内的 多个线程。

2，如果进程中的一个进程被堵塞，它 能够切换同一进程内的线程继续执行（用户级线程的一个缺点）。

3，所有能够堵塞线程的调用都以系统调用的形式实现，代价可观。

4，当一个线程堵塞时，内核根据选择运行另一个进程的线程，而用户空间实现的线程中，运行时系统始终运行自己进程中的线程。

5，信号 是 发给 进程 而不是线程的，当一个信号到达时，应该由哪一个线程处理它？ 线程 可以 “注册” 它们感兴趣的信号。

### 缺点：

1，由内核进行调度 （待考究）

## 用户级线程 VS 内核级线程

1，内核支持线程 是 OS 内核可感知的；

​      用户级线程 是 OS 内核不可感知的。

2，用户级线程的创建、撤销 和 调度 不需要 OS 内核的支持，是在 语言 （JaVa）这一级处理的；

​      内核支持线程创建、撤销 和 调度 都需要OS 内核提供支持，而且与进程的创建、撤消 和 调度 大体是相同的。

3，用户级线程执行系统调用命令时 将导致其所属进程被中断；

​      内核支持线程执行系统调用指令时，只导致该线程被中断。

4，在只有用户级线程的系统内，CPU 调度 还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮转运行；

​       在由内核支持线程的系统内，CPU 调度则以线程为单位，由 OS 的线程调度程序负责线程的调度。

5，用户级 线程的程序实体是运行在用户态下的程序；

​      内核支持线程的程序实体则是可以运行在运行状态的程序。

# 协程 **

参考：

-   https://www.cnblogs.com/chenny7/p/4498322.html
-   https://blog.csdn.net/qq_27384769/article/details/80994473

背景：一种 特殊性 用户空间线程，调度是由程序员自己写程序来管理，对于内核来说是不可见的。

特点：

1，协同，因为是由程序员自己写的调度策略，其通过协作而不是抢占来进行切换。

2，在用户态完成创建，切换 和 销毁。

3，从编程角度上看，协程的思想本质就是 控制流的 主动让出（yield）和 恢复（resume）机制。

4，genertator 经常用来实现协程。

## golang 之 协程

```
优点：
1，与线程相比，go 协程的开销非常小。Go 协程的堆栈大小只有 几KB，它可以根据应用程序的需要而增大和缩小，而线程必须指定堆栈的大小，并且堆栈的大小是固定的。

2，go 协程被多路复用到较少的 OS 协程。一个程序中数千个 go 协程 可能只运行在一个线程中。如果线程中任何一个 go 协程发生堵塞，go 会创建一个新的 os 线程并将其余的 go 协程移动到新的 OS 线程。

3，go 协程之间通过 信道（channel）进行通信。信道可以防止多个协程访问共享内存时发生竟险。信道可以想象成多个协程之间通信的管道。
```

# 进程同步 *

## 1，临界区

临界区：对 临界资源 进行访问的那段代码

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

### 2，同步 与 互斥

同步：多个 进程 按照一定的顺序执行。

互斥：多个 进程 在同一个时刻只能有一个进程 进入临界区。

## 3，信号量

信号量：一个整形变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

-   down：如果信号量大于 0，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
-   up：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是：在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了  **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

4，管程

特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则，其他进程永远无法使用管程。

# 进程同步 *

参考：

-   https://blog.csdn.net/wuhuagu_wuhuaguo/article/details/78591330
-   https://www.cnblogs.com/Forever-LJX/p/5803528.html

## 1，信号量

出现背景：为控制一个具有有限数量用户资源而设计。

它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问次资源的最大线程数目。互斥量 是 信号量的一种特殊情况，当信号量的最大资源数 = 1 就是互斥量了。

```
优点：

1，适用于 对 Socket 程序中线程的同步。
场景：网络上的 HTTP服务器 要对 同一时间内访问 同一页面的用户数 加以限制，只有不大于设定的最大用户数目的线程能够进行访问，而其他的访问企图则被挂起，只有在有用户退出对此页面的访问后才有可能进入。

缺点：

1，信号量机制必须有公共内存，不得用于分布式系统，这是它最大的缺点。

2，信号量机制功能强大，但 使用时对信号量的操作分散，而且难以控制，读写 和 维护都很困难，加重了程序员的编码负担。

3，核心操作 P-V 分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。
```

## 2，管程

概述：管程是一种程序结构，结构内的多个子程序形成的多个工作线程互斥访问共享资源。管程实现了在一个时间点，最多只有一个线程在执行管程的某个子程序。

特性：任意时刻莞城中只能有一个活跃进程，这一特性使管程能有效地完成互斥。

典型实现：当一个进程调用管程过程时，该过程中的前几条指令将检查在管程中是否有其他的活跃进程。如果有，调用进程将被挂起，直到另一个进程离开管程将其唤醒。如果没有活跃进程在使用管程，则该调用进程可以进入。

```
语言角度细究：

1，模块化。管程使一个基本程序单位，可以单独编译。

2，抽象数据类型。管程中不仅有数据，而且有对数据的操作。

3，信息掩蔽。管程外可以调用管城内内部定义的一些函数，但 函数的具体实现外部不可见。
```

## 3，互斥量

出项背景：为协调共同对一个共享资源的单独访问而设计的。

互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。

```
优点：
1，在 同一应用程序 不同线程中实现资源的 安全共享。
2，在 不同应用程序的 线程之间实现对资源的 安全共享。

缺点：
1，互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话，使用临界区会带来速度上的优势并能够减少资源占用量。因为：互斥量 是 跨进程的，互斥量一旦被创建，就可以通过名字打开它。

2，通过互斥量可以指定资源按被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理。
案例：现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。
```

# 进程通信 *

参考：

-   https://www.cnblogs.com/inception6-lxc/p/9073983.html

## 1，管道

概述：管道使单向、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连在一起。管道提供了简单的流控制机制。

```
特点：
1，写进程在管道的尾端写入数据，读进程在管道的道端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

2，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。

3，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

4，无名管道只能实现父子或者兄弟进程之间的通信，有名管道（FIFO）可以实现互不相关的两个进程之间的通信。
```

实现案例：用FIFO让一个服务器和多个客户端进行交流时候，每个客户在向服务器发送信息前建立自己的读管道，或者让服务器在得到数据后再建立管道。使用客户的进程号（pid）作为管道名是一种常用的方法。客户可以先把自己的进程号告诉服务器，然后再到那个以自己进程号命名的管道中读取回复。

## 2，套接字

概述：套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。

## 3，消息队列

概述：消息队列是一个在系统内核中用来保存消息的队列，它在系统内核中是以消息链表的形式出现。

优点：

1，消息队列克服了信好传递信息少、管道之恶能承载无格式字节流以及 缓冲区大小受限 等特点。

## 4，信号量

概述：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。

优点：它 主要作为进程间 以及 同一进程内不同线程之间的同步手段。

## 5，共享内存

概述：共享内存允许两个或多个进程访问同一个逻辑内存。这一段内存可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程读取。通过一个简单的内存读取读出，从而实现了进程间的通信。

```
特点：
1，如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。

2，共享内存是最快的IPC方式，它是针对其它进程间通信方式运行效率低而专门设计的。

3，共享内存往往与其它通信机制（如 信号量）配合使用，来实现进程间的同步和通信。
```

# 死锁 *

-   https://blog.csdn.net/triorwy/article/details/80643753
-   https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md



概述：

1，针对进程：进程的死锁是 指当两个或者多个进程互相持有对方所需要的资源，但双方都不释放资源，使得双方都处于等待状态，无法前往执行，从而产生死锁。

2，针对线程：线程的死锁是指当多个线程去申请临界资源时申请公共的锁，可能两者在申请相互的锁，导致两者被挂起，这样就产生死锁了

## 必要条件 - 产生原因

-   互斥 和 不共享：每个资源 要么 已经分配给了一个进程，要么是 可用的。
-   占用 和 等待：已经得到了某个资源的进程可以再请求新的资源。
-   不可抢占：已经分配给一个进程的i资源不能抢占性地被抢占，它只能被只有它的进程显示地释放。
-   环路等待：有两个 或 两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占用的资源。

## 处理方法

主要有一下四种方法：

-   鸵鸟策略
-   死锁检测
-   死锁预防
-   死锁避免

## 鸵鸟策略

比喻：把头埋在沙子里，假装根本没有发生。（假装看不见）

原因：因为解决死锁问题的代价很高，因此 鸵鸟策略这种不采取任务措施的方案可以获得更高的性能。

处理场景：当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法也仅仅是忽略它。

1，每种类型一个资源的死锁检测

解决：每种类型一个资源的死锁检测算法 是 通过检测有向图是否存在环来实现的，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就检测到死锁的发生。

2，每种类型多个资源的死锁检测

==找不到合适的概述

3，死锁恢复

-   利用 抢占 恢复
-   利用 回滚 恢复
-   利用 杀死进程 恢复

## 死锁预防

在程序运行之前预防发生死锁。

#### 1，破坏 互斥 和 不共享 条件

例如 打印机计数允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

#### 2，破坏 占有  和  等待 条件

一种实现方式 是 规定所有进程在开始执行前请求所请求的全部资源。

```
缺点：
1，系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。

2，还会导致“饥饿”现象，当由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。
```

#### 3，破坏 不可抢占 条件

当一个进程保持某些不可剥夺资源时，请求新的资源时得不到满足，它必须释放已经保持的所有资源，待以后需要时再重新申请。 

```
缺点：
1，实现起来太复杂，释放已获得资源可能造成前面所做的工作不起作用。

2，在请求和释放资源的过程中开销太大，降低了系统的吞吐量。

3，这种方法常用于状态易于保存和恢复的资源。如CPU中的寄存器和内存资源，一般不能用于打印机类资源。
```

#### 4，破坏 环路 等待

可采用线性资源分配法，给资源 统一编码，进程 只能按编号顺序来请求资源。

```
缺点：
1，编号必须相对稳定，如果有新设备增加时，它的顺序就可能要发生变化，这就造成了多余工作量。
2，经常会发生作业使用顺序和规定系列号顺序不一样，造成资源的浪费。
3，这种规定顺序申请资源的方法必然会给编程者带来麻烦。
```

## 死锁避免

在程序运行时避免发生死锁。

### 1，安全状态 -线性资源分配法

```
这种算法资源必须按照某种规则给系统中的所有资源统一编号（例如打印机为1、磁带机为2、磁盘为3、等等），申请时必须申请序列号高的资源。系统要求申请进程： 
1、对它所必须使用的而且属于同一类的所有资源，必须一次申请完； 
2、在申请不同类资源时，必须按各类设备的编号依次申请。例如：进程P1，使用资源的顺序是R1，R2； 进程P2，使用资源的顺序是R2，R1；若采用动态分配有可能形成环路条件，造成死锁。 
采用有序资源分配法：R1的编号为1，R2的编号为2； 
P1：申请次序应是：R1，R2 
P2：申请次序应是：R1，R2 
这样就破坏了环路条件，避免了死锁的发生
--------------------- 
作者：Triorwy 
原文：https://blog.csdn.net/triorwy/article/details/80643753 
```

### 2，系统安全状态法

即在系统分配资源之前，就应该检测此次资源分配的安全性，如果此次分配资源会导致进程进入不安全状态，那就等待，如果不会，则分配资源。

### 3，银行家算法

```
四个条件： 
1. 分批向银行贷款时，申请的总额不能超过一开始申请的额度。 
2. 申请贷款时不能超过银行现有资金数目 
3. 当银行资金不能满足顾客贷款需求时，可以推迟支付，但是肯定会让顾客在需求时间内得到贷款 
4. 顾客拿到贷款后必须在规定时间内归还。
--------------------- 
作者：Triorwy 
原文：https://blog.csdn.net/triorwy/article/details/80643753 
```

# 虚拟内存 *

参考：

-   https://sylvanassun.github.io/2017/10/29/2017-10-29-virtual_memory/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io

## 概述

前提：一个进程是与其他进程共享 CPU 和 内存资源的。正因如此，操作系统需要有一套完善的内存管理机制才能防止进程之间内存泄漏的问题。

虚拟内存：为每个进程提供一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。

```
它的重要意义：
1，它定义了一个连续的虚拟空间，使得程序的编写难度降低。

2，把内存扩展到硬盘空间只是使用虚拟内存的必然结果，虚拟内存空间会存在硬盘中，并且会被内存缓存（按需）。

3，有的操作系统还会在内存不够的情况下，将某进程的内存全部放入硬盘空间中，并再切换到该进程时再从硬盘读取。（这也是为什么Windows会经常假死的原因…）。

主要功能：
1，它把主存看作为一个存储在硬盘上的虚拟地址空间的高速缓存，并且只在主存中缓存活动区域（按需缓存）。
2，它为每个进程提供了一个一致的空间，从而降低了程序员对内存管理的复杂性。
3，它还保护每个进程的地址空间不会被其他进程破坏。
```

## 总结

MMU ： 内存管理单元

PTE ：页表条目

虚拟内存是内存的一个抽象。支持虚拟内存的CPU 需要通过虚拟寻址的方式来引用内存中的数据。CPU加载一个虚拟寻址，然后发送给 MMU 进行地址翻译。地址翻译需要硬件与操作系统之间紧密合作，MMU 借助页表来获得物理地址。

虚拟内存系统简化了管理，连接，加载，代码和数据的共享 以及 访问全新的保护：

-   简化链接，独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。
-   简化加载，虚拟内存使向内存中 加载可执行文件和 共享对象文件变得更加容易。
-   简化共享。独立的地址空间为操作系统提供了一个 管理用户进程 和 内核 之间共享的一致机制。
-   访问权限保护。每个虚拟地址都要经过查询 PTE 的过程，在PTE 中设定访问权限的标记位，从而简化内存的权限保护。

# 页面置换算法 *

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页面调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已存在的缓存，这样才能有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

## 1，最佳

>    OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

## 2，最近最久未使用

>   LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

## 3，最近未使用

>   NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

-   R=0，M=0
-   R=0，M=1
-   R=1，M=0
-   R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

## 4，先进先出

>   FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

## 5，第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去。为避免，先对该算法做个简单的修改。

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最久页面的 R 位。如果 R 位是 0，那么这个页面既久又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

## 6，时钟

>   Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

# 分页 与 分段 *

## 分页

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

## 段页式

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

## 分页 与分段的比较

-   对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。
-   地址空间的维度：分页是一维地址空间，分段 是 二维的。
-   大小是否可以改变：页的大小不可变，段的大小 可动态变换。
-   出现的原因：
    -   分页主要用于实现虚拟内存，从而获得更大的地址空间；
    -   分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

# 静态链接 与 动态链接 *

参考：

-   https://blog.csdn.net/kang___xi/article/details/80210717

## 静态链接

### 出现原因：

```
实际开发中，不可能将所有代码都放在同一个源文件中，所以会出现多个源文件，而且多个源文件之间不是独立的，而是会存在多种依赖关系，为了满足依赖关系，则需要将这些源文件产生的目标文件进行链接，从而形成一个可以执行的程序。
```

### 原理：

```
由很多目标文件进行链接形成的使静态库，反之，静态库可以简单地看成是一组目标文件的集合，即很多目标文件经过压缩打包形成后的一个文件。

链接器在链接静态链接库的时候是以目标文件为单位的。
```

### 优缺点：

```
缺点：
1，浪费空间。因为每个可执行程序中对所有需要的目标文件都要由一份副本，所以，多个程序对同一目标文件都有依赖。
2，更新困难。每当库函数的代码修改了，这个时候就需要进行编译链接形成可执行程序。

优点：
1，运行速度快。在可执行程序已经具备所有可执行程序所需要的任何东西。
```

### 如何重定位？

静态重定位是在 目标程序装入内存时，由 装入程序对目标程序中的 指令和 数据的地址进行修改，即把程序的逻辑地址都改成实际的地址。对每个程序来说，这种地址变换只是在装入时一次完成，在程序运行期间不再进行重定位。

```
优点：
1，无需增加硬件地址转换机构，便于实现程序的静态连接。在早期计算机系统中大多采用这种方案。

缺点：
1，程序的存储空间只能是连续的一片区域，而且在重定位之后就不能再移动。这不利于内存空间的有效使用。

2，各个用户进程很难使用 共享内存中的同一程序的副本。
```

## 动态链接

### 出现原因：

```
解决静态链接中的两个问题：一，空间浪费。二，更新困难。
```

### 原理：

```
基本思想：把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。
```

### 优缺点：

```
优点：
1，即使需要每个程序都依赖同一库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；

2，更新方便。更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

缺点：
1，性能损失。因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接。据估算，动态链接和静态链接相比，性能损失大约在 5%以下。
```

### 如何重定位？

动态链接把链接过程推迟到了程序运行时，但是在形成可执行文件时，还是需要用到动态链接库。（注意形成可执行文件和执行程序是两个概念）

比如我们在形成可执行程序时，发现引用了一个外部的函数，此时会检查动态链接库，发现这个函数名是一个动态链接符号，此时可执行程序就不对这个符号进行重定位，而把这个过程留到装载时再进行。

```
优点：
1，程序占用的内存空间动态可变，不必连续存放在一处。

2，比较容易实现几个进程对同一程序副本的共享使用。

缺点：
1，需要附加的硬件支持，增加了机器成本，而且实现存储管理的软件算法比较复杂。现在一般计算机系统中都采用动态重定位方法。
```

