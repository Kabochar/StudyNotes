并发模块（进程、线程、协程、通信、同步）：

-   进程、线程的区别
-   系统线程和用户线程的区别
-   CPU 时间片分配方式
-   协程基本原理、优点和缺点
-   上下文切换以及对性能的影响
-   通道基本原理
-   同步通道和异步通道的区别
-   Goroutine 资源泄漏
-   常见同步方式
-   互斥锁（Mutex）
-   读写锁（RWMutex）
-   条件锁（Cond）
-   信号量（Semaphore）
-   自旋锁（SpinLock）
-   原子操作（Atomic）
-   单核和多核指令是否原子
-   如何实现原子操作
-   CAS（Compare-and-swap）
-   用原子操作实现自旋锁

## 第05课：连续栈

对于 Goroutine 这种栈和系统栈实际上有很大区别。因为 Goroutine 栈是对象自带的，G 对象自带这种栈，然后在执行时候这个栈会绑定 M，因为初始化只有 2K，创建成千上万 G 任务因为消耗非常小，但是去执行的时候栈 2k 可能不够用，不像操作系统系统默认情况下 M 可能是 10M，2k 很容易就不够用。

Goroutine 栈空间在不够用的情况下必须做扩容 Grow，扩容有两种方式，一种叫分段模式，一种叫连续模式。

### 什么是分段栈

分段模式其实很简单，比如说一段当前栈，当我们需要扩容的时候再分配一个栈空间，构成链表结构，当前栈不够用的时候直接分配新的再新的上工作就可以了，新的工作完了以后就抛弃掉回到当前栈。

分段模式的优点是当前栈上面的数据不需要任何处理，只需要把新的栈帧分配到新的栈空间就行了，然后执行完把这段空间抛弃掉就可以了。

### 分段栈的问题是什么

分段栈带来的问题是执行一个 for 循环，在内部分配空间的不够用，必须要分配新的栈帧，执行结束的时候新的栈帧释放，这样会造成每次循环都要创建、释放、创建、释放，频繁的分配内存和释放内存，就会形成一个热点效应，这种热点效应会导致程序性能下降的非常严重。

分段模式会存在热点效应，这个热点效应在某些时候会造成很严重的性能问题，所以 Go 语言从 1.4 版本就抛弃了分段栈的概念而改用新的方式叫连续栈。

### 连续栈如何实现

连续栈如何实现，比如一段当前栈空间，当内存不够的时候，它会在另外的空间创建原来 2 倍大小的栈空间，然后把当前栈的数据全部复制过来。

分配了 2 倍空间，原来的空间被抛弃掉，接下来 for 循环执行的时候新的空间显然是够用的，这个时候就不会形成热点效应。

### 连续栈回收

在 for 循环的时候如果是分段栈每次都需要做分配操作，而对于连续栈来说可能做一次分配操作等垃圾回收时候去做收缩操作就可以了，显然对于 for 循环本身不需要做多次内存分配操作，这就是它在性能上有所提升的原因。

归根结底 Runtime 所有的理论还是**空间换时间**，即宁可浪费空间来提升执行效率。

现代操作系统这种抽象会让我们编程变得越来越简单，有很多原来需要做的事被操作系统和 Runtime 监管了。

分段栈的优点对于内存比较节约，因为不用内存释放，缺点一旦形成热点效应时候性能会比较差，因为每次都需要去分配、释放、分配、释放。

连续栈的优点就在于一次性创建一大块空间后面不需要重复分配，缺点就会有一定的内存浪费。

## 第06课：系统监控

### 系统监控的用途

系统监控本身是一种守护方式来确保有些事情必须要处理。

Runtime 三大组件，内存分配器、垃圾回收器、Goroutine 调度，实际上除此之外还有系统监控这样一个任务再后台一直在跑！WHY？

### 强制垃圾回收

第一个作用确保垃圾回收肯定被执行，因为垃圾回收器可能会因为某种原因没办法触发；

系统监控程序会定期的检查上次垃圾回收器什么时候执行的，如果发现已经有很长时间没有执行垃圾回收操作了，它就强制执行一次回收。确保当这个预值触发不了的时候总有其他的机制来保障垃圾回收得以正常运行。这是一种保障，也称之为守护。

### 释放物理内存

第二个作用是在内存分配以后，Heap 中存在大量的自由内存块，这些内存块在高峰时候在低峰时候全部不使用了，这些不使用的自由内存块有可能做了物理映射，所以系统监控程序会定期扫描这些内存块，它会去检查如果这些自由块有 5 分钟预值都没有使用过，闲置时间比较长，它就会建议操作系统去解除物理映射，这样就有机会把物理内存释放掉。

注意内存分配器并不关心内存释放操作，它只关心内存复用，真正的内存释放操作实际上是后台监控程序来完成的。它来定期扫描自由内存块，如果长时间不用，它就会建议操作系统把物理内存收回去，至于操作系统收不收跟它无关，它只是向操作系统发出建议。

### 抢占调度

Go 语言做了一种很简单的调度操作，它是怎么做的呢。这不是执行很长的操作么，内部调用任何一个函数都得去 call 那个函数，它就在函数头部插入一段汇编指令，sub 栈帧分配之前我们会发现有些指令，这些指令其实是由编译器插入的，它做两件事。第一件事用来判断栈帧空间够不够用，不够用进行扩张，第二件事用来检查当前的 G 执行多长时间了，如果时间很长了而且系统调度发出了抢占通知，它会立即中止这个 G 任务执行，把那些状态打包，打包以后把这个 G 任务放入队列，这样这个 P、M 就有机会去执行其他的 G 任务。

大白话，向函数头部插入指令只要 G 执行其他函数那么就有机会执行我们插入的指令，那些指令判断两件事，第一件事栈空间够不够用，不够用就扩张，第二件事判断一下是不是要做抢占调度，如果发现要做抢占调度的话就把当前这个 G 状态保存下来，然后把这个 G 丢回到任务队列去，然后让当前 P、M 去执行其他 G，这样来确保通过抢占调度实现相对公平。

缺点是什么？假如 for 循环内部不调用任何函数或者调用的函数被内联进来了，这样的话永远都不能执行头部这些指令，依然没有机会释放，所以这种抢占调度其实是一种伪机制，因为它毕竟不是操作系统内核的 CPU 时间片的概念，它还是协商机制，所以几行指令实际上要编译器插入。

Go 语言执行的是机器码，机器码执行时候是由操作系统控制的，它没有办法像解析器一样。

### 处理系统调用

处理系统调用就是系统监控会把耗时很长时间系统调用的 G 抢回来。

### I/O 事件

Go 的一些 I/O 事件严格意义上来说都是属于异步的，I/O 事件处理后得返回，返回以后得去检查是不是执行结束了，所以这也是系统监控的责任。

## 第07课：进程、线程

### 进程、线程的区别

什么叫程序？程序是运行一段代码所需所有资源的总和，进程是程序启动后的状态。

进程严格上说也是资源的集合，相对于程序静态资源来说它更多的是动态资源，进程很显然是一种资源单位，操作系统为资源单位做管理。

和 CPU 打交道的东西，称之为`线程`，线程是由进程的组成，线程在进程里面专门负责执行指令，指令是从进程 .text 段映射里读出来的，然后在进程里堆栈上操作一些数据，线程处理数据的资源边界是在进程内的。

总结起来就是进程是一种资源单位，操作系统按照进程来分配资源管理资源，线程是进程内的，专门用来执行。

每个进程最少有一个线程，否则 CPU 没法执行。

### 系统线程（内核线程、内核态）和用户线程的区别

线程我们严格意义上来说通常指的是任务加上它执行所需的资源，才称之为线程，如果线程只是执行单位没有任何资源，我们把它称之为纯任务，它是可复用的而线程本身实际上是有状态的，因为线程执行的时候实际上是有线程栈，所以说任务加上线程栈类似这样一些资源我们把它称之为线程。

那么`系统线程`说白了就是操作系统提供的这样的任务单元，`用户线程`指的是在用户空间实现的一些这样的并发任务，跟操作系统没关系。

### CPU 时间片分配方式

操作系统看不到用户空间层面上的用户线程，操作系统根本不关心。

操作系统关心的是两个执行单位，给执行单位分配时间片，至于它们俩共享资源和分配时间片无关，因为操作系统不关心享有了多少资源享有谁的资源，关心的就是两个独立的执行单位，给每个都分配时间片。

当你选择一门语言或者一种并发库时候必须知道它究竟是由系统线程实现的还是用户线程实现的，系统线程很显然在多核上直接可以被分配到多核上去，用户线程实际上只有一个实际上只能分配到一个核上，这地方有很大的差别。

当从用户态代码进入系统态代码调用的时候会涉及到上下文切换，这是要付出一定的代价的。很显然系统线程去创建去调度是要付出这些代价的，所以很多时候系统线程成本会非常的高，当我们频繁的去创建系统线程销掉系统线程这种代价实在太大了。

在用户态抽象很多个执行单位，我们把这些用户态线程映射到少量的系统线程上面去，然后建立类似于 Pool 这样的一个概念可以复用的。这样的好处是我们把建成 Pool 以后就不需要频繁的创建系统线程，只需要用户态去创建各种各样我们所需的这种抽象的专门用来存储状态的这种用户态线程，我们可以创建很多个，当我们创建好当需要执行的时候，把它绑定到一个系统线程上面去，然后去执行执行完了以后可以把这个系统线程释放掉，系统线程回到 Pool 里面只需要把这个状态杀掉，我们不需要消灭这个系统线程。因为接下来我们可以把另外一个任务重新的调度到这个系统线程上去执行。

首先我们创建一定数量的系统线程，创建好了这些系统线程专门用来做执行的。第二，我们额外在用户态空间创建一些对象专门用来保存执行时候所需要的状态，其中包括线程栈，它不负责执行，因为它只是抽象的一个很普通的数据容器，它执行的时候把它绑定到某个系统线程上去，这样这个线程就具备了普通线程那种状态然后执行，执行完了这个线程上的状态全部被剥离掉然后这个线程就变成干净的了原始状态接下来可以执行其他的任务。

所以呢，在现代语言当中往往会在系统线程之上做一次抽象，就是在用户态空间去实现大量的专门用来保存状态的这种用户线程，用户线程不负责执行它只负责保存用户状态，所有的执行最终交给底层的系统线程执行，所以底层去实现类似像并行，用户态我们只需要创建像大量的并发任务，中间通过调度器来实现这两个层面上的绑定从而实现把用户态这样的执行和系统态这样的执行分离掉，避免反复的系统调用所消耗的资源。

**实际的运用当中我们往往会把很多东西去结合起来尽可能发挥它的优势来避免它的缺陷，在任何时候没有任何一个人能告诉你什么设计是好的什么设计是不好的，你必须要做出大量的积累然后去设计出一种相对来说比较和谐的执行方式，尽可能发挥所有机制的优点来隐藏它的缺点。**

### 总结

如果我们不在底层分配足够多的系统线程的话那么它很麻烦只能被一个核使用，而且它在CPU时间片上会很麻烦，因为少，很显然比如A进程有两个系统线程，B进程有两个用户线程只有一个系统线程，那么在时间片分配上绝对不公平，归根结底是用户线程操作系统根本看不到，因为它是一个很抽象的概念不是操作系统提供的，操作系统根本不理解用户线程是什么。

## 第08课：协程和上下文切换

### 协程基本原理，优点和缺点

在操作系统以外用户空间再实现一次调度，它每次浪费的时间片都捡回来尽可能去执行我们的代码，我们可以把这种机制称之为协程，就是它比线程粒度更小。

在用户空间实现多任务的调度而多任务调度是发生在一个线程上的，我们把这种机制称之为协程。

协程很显然是串行的它不是真正意义上的并行，实际上是执行 A 任务当 A 任务阻塞的时候然后唤醒 B 任务，B 任务完了以后可能做一次检查看 A 的结果回没回来，很显然它这种切换来实现多任务并发，协程本质是串行的。

协程有什么好处？

假如 A 和 B 都共享一个变量 x 的时候，A 和 B 需要不需要加锁，因为它们不可能同时执行，所以协程很多时候不需要做锁的处理的；

第二个因为这种调度机制是我们自主去实现的，我们可以有很多种不同的方式，比如说 A 执行到一个节点的时候去唤醒 B，或者 B 执行完一个节点时候去唤醒 A，A 和 B 可以自己决定什么时候把控制权交出去，就是可以把一个逻辑执行到一个相对安全的点然后给交出去。

所以这种操作系统这种抢占机制，协程更多的实现`协商机制`，自己决定什么时候交出去，因为操作系统没办法去抢。

不同的协程在调度器里面有不同做法，协程要看怎么去实现，哪种方式是合理的，每种语言都有自己的选择。

### 上下文切换（Context Switch），以及对性能的影响

这种上下文切换其实是像 VA 那种换入换出有些类似，是有保存场景和恢复场景，都需要有代价的，上下文切换我们说：一种，进程级别的；另一种，线程级别的；还有一种，中断引起的，中断是操作系统一种概念；还有一种，各种各样的底层驱动程序引发的，这些都是很被动的，另外有些是种主动的，执行系统调用其实就是发生一种中断，调用一段系统调用的时候，这个执行是从用户空间进入系统空间。

不管怎么做上下文切换都会带来很大的性能损失，不管进程级别的还是线程级别的还是主动系统调用而引发的都会造成一定的性能损失，一些书的时候大家都会这样提醒，尽可能的减少系统调用实际上就是要减少上下文切换带来的性能损失。因为很多离 CPU 很近的一些资源比如说 L 级的 Cache，寄存器的数据都要写回到主存里面去，而系统代码执行完了都要把这些东西读回来，相对 CPU 这种执行速度来说从主存操作数据是很慢的，所以这都是要付出代价的。

上下文切换到底什么原因引起的？所以得花点时间去搞清楚现在用的这些操作系统是怎么管理进程的，怎么管理线程的，怎么样给线程分配时间片的，然后线程优先级怎么确定的，这个上下文切换到底需要付出多大的代价，有哪些原因会引发上下文切换，可能不需要对操作系统了解非常多，但这些东西必须要了解，因为程序执行的时候会跟这些东西息息相关，这甚至决定了程序是否使用多进程模型。

## 第09课：通道

### 通道基本原理

如果我们希望可以把某些调度固定到某些核上面避免频繁这种上下文切换，可能会采用多进程模型，而多线程尤其系统线程可以让我们更多的获得时间片，协程则是在单个时间片上尽可能减少时间片的浪费。

从编程开始我们就知道，事情往往是被抽象，抽象成不同的状态，我们实际上是屏蔽底层的一些东西，包括网络通讯我们都应该屏蔽的，那么可以从几个方面来看一下，究竟网络传输也好，数据共享也好，哪种方式，该怎么选择，依然是我们的架构和逻辑有关系。

最简单的方式，一个数据可以被 G1、G2 共享，这是一种最简单的状态，这种状态实际上是多线程去找局部线程共享一个变量。

还有类似的方式是在多进程之间，假如一个父进程创建两个子进程，那么如果在父进程中用 mmap 创建一个内存块，这个内存块可以声明为多个子进程共享的，这种方式可以实现在两个进程之间去共享同一块内存，这样也是在多进程之间交换数据的方法。

还有两种方式并发模型，第一种像 Erlang 语言最常见的 Actor，另外一种是 Go 语言的 Channel 模型。实现用通讯来代替内存共享这样的方式，我们把这种方式通常称之为类似 CSP 模型。

Actor 模型其实很关心的是你把消息打包以后扔到哪个 MailBox 里面去，它关心的是谁接收这个事情，至于这中间怎么传输的，是本机的内存共享传输还是跨机器网络传输还是用其他方式它并不关心。所以它天生就是异步的，就像你发送邮件肯定不需要对方当前实时接收，它天生就是异步的，你把邮件发送到对方的信箱里就可以了，至于接下来怎么处理那就跟你无关了。

Go 语言的 Channel 模型和它有区别的，它关心的是数据被放到哪个管道里面去了，至于后面谁接收，几个人接收都跟它无关，它不关心这个，它只关心把这个数据放入正确的通道里。所以从本质上来说它天生就是同步的，因为通道本身实际上就是有状态的。

Actor 模型关心的是你交给谁，那个人具体我不关心，我只知道它有具体的 MailBox。Channel 模型关心的是你放到哪个通道里去了，这个通道最终由谁处理由几个人来处理跟你无关。

Channel 这种模型很多时候可以做类似的实时计算，而 Actor 模型很适合做天生的分布式模型

当你选择内存共享也好还是 Channel 也好归根结底和你的需求有关系，相比较内存共享它的抽象度更高，缺点就是性能上要付出额外的代价。

### 同步通道和异步通道的区别

Channel 通道怎么做的，它实际上有两种方式，一种称之为同步方式，一种称之为异步方式。

同步方式给人的感觉是缓冲区为零的这种通道，也就意味着我不会在缓冲区存任何东西，实际上这个通道会关联两个队列，一个是等待队列，一个是发送队列，这是在同步方式下典型的工作方式。

通道只是确定生产和消费双方的角色，但是并不关心对方的身份，所以同步方式虽然需要配对，但依然是低耦合的。因为你并不需要知道对方的身份，你只需要把数据给它就可以了，至于对方是哪个对象跟你没关系。

异步方式、生产方和消费方都围绕着数据槽来进行操作，如果数据槽为空或者不为空，他们就是异步的，只有生产方发现满了就会阻塞，消费方槽里没数据就得阻塞。不管是哪方不管是拿走数据还是放入数据时候都有责任唤醒另一方的等待队列，至于最后究竟谁激活了跟你没关系。

所以这个时候得搞清楚异步方式下面他们围绕着是这个槽，如果我们把这个槽的数量变成零，其实它就变成了同步方式。区别就是数据放入槽里面还是私下进行交换，异步方式通过槽来交换，你依然不需要对方到底是谁。这是同步方式和异步方式很简单的实现模型。

### 总结

以后设计架构的时候，先不要一股脑的砸在用什么技术去实现，一上来就搞个数据库 Redis 之类的，先不要去想这些，也不要想进程内的还是进程外的，首先用这种抽象模型从逻辑上是通的，然后再去考虑用什么样的技术去实现。这是两码事，不要一上来就把脑袋砸在代码上，那样就不是在做架构了。

## 第10课：Goroutine 架构设计

### Goroutine 资源泄漏

资源泄露最常见的是 Goroutine 泄露，我们通常会把发送和接收分成两个并发单元，如果发送单元被放到队列休眠了，一堆发送单元都在这里休眠没有任何接收方来唤醒，那么这些 Goroutine 永远不会结束，这就是资源泄露。

但积累很多的话所有栈空间需要扫描 GC 的根，最后会导致垃圾回收器效率会很低，一旦泄露非常严重的时候依然会导致很严重的问题，所以 Goroutine 发送和接收的平衡要非常的小心。

下面用一个例子说明资源泄露怎么形成的：

```
// leak.go
package main

import (
    "runtime"
    "time"
)

func test() {
    c := make(chan int)

    for i := 0; i < 500; i++ {
        go func() {
            c <- 1
        }()
    }

    // go func() {
    //  for x := range c {
    //      _ = x
    //  }
    // }()
}

func main() {
    test()

    for i := 0; i < 60; i++ {
        runtime.GC()
        time.Sleep(time.Second)
    }
}
```

没有任何的接收，也就意味着这 500 个发送方都在发送队列中进行休眠，因为没有任何人来唤醒它，这就形成很典型的资源泄露，资源泄露的话垃圾回收器是没有办法的。

```
$ go build -o **test** leak.go
$ GODEBUG="gctrace=1,schedtrace=1000,scheddetail=1" ./**test**
```

怎么样去处理资源泄露呢？

Goroutine 并不关心有多少人发送多少人接收，只要能处理完就可以了。

第一种方式需要有接收方，第二种方式发送方可以设计超时，发送的数据如果超过 10s 都没有办法接收的话那么就把 Goroutine 结束掉。

需要注意一点是，发送和接收必须要配对，至于多个人发送方发送一接收方接收循环没有关系，数量可以不相等，只要最终把所有排队的发送方配对消费完。第二种方式是没有接收方，发送方都有超时，就是发送方可以等，但是等 10s 以后依然没有配对的话那就放弃，这也是一种方式。

### 架构设计

基于通道的方式或者基于消息队列的方式来实现消息的传递，我们管这种方式叫做 CSP 模型，CSP 模型简单来说用通讯来代替内存共享。因为通讯本身可以扩展的，最简单的通讯是发送一个事件或者发送一个信号，然后来复制内存，甚至不用复制内存。

拷贝数据有两种方式来拷贝，一种方式拷贝是发送方把数据完整的复制一份交给接收方，实际上就是两块内存；第二种方式是使用同一块内存，发送方把指向内存的指针传给接收方，传给接收方以后发送方就不再持有这个指针，只有接收方持有这个指针。

优点是当这个数据很大的时候可以避免内存复制的开销，也避免在堆上创建两个对象。

通讯代替内存共享并不意味着不用内存共享，所谓的内存共享指的是生产和消费同时持有某个数据才叫共享。

>    如果同一块内存的引用转移给另外一方，这也叫一种通讯，不要很教条化的理解通讯，转移指针也是一种通讯。

## 第11课：常见同步方式

### 常见同步方式

当两个并发单元共享同一个数据的时候需要做**同步**处理，同步处理并不局限于共享同一块内存，当两个进程共享同一个文件给文件加上锁也叫做同步处理。

共享同一资源都会产生数据竞争，这个时候都需要做同步处理。

### 锁

为了数据竞争我们需要加个锁，它们有不同的性能差别，也就意味着不同的锁适合用在不同的场合，任何时候锁的选择都会很性能有很大关系。

### 互斥锁（Mutex）

互斥就是每次仅允许一个人操作，不区分读写操作，除非这个人把锁给放掉，释放了锁别人才能拿到，否则其他人都得等。

互斥操作有两种实现方式，一种是由内核实现的，一种是由 Runtime 实现的，内核实现的意味着当阻塞的时候内核时间片会被拿走，Runtime 实现的话意味着执行序会被拿走。无论怎么实现都会涉及到上下文切换，所以相对来说代价会比较大。

互斥锁有个特点是递归锁，什么叫递归锁呢？假如 T1 拿到了这把锁，那么接下来再在 T1 上加锁可以么？对于大多数语言是可以的，例如 Java。

但不是所有的语言都支持递归锁。以 Go 语言为例，Go 语言的每个并发单元不是线程，是个 Goroutine，当 G1 拿到了这把锁，它并不能绑定到某个固定的线程上，它有可能中途某种原因被调度到队列，下次被 T2 拿到，那么这把锁实际上是在不同线程当中进行转移。Goroutine 的特点就是它并不会和一个线程进行绑定，它中途会重新放回队列然后在另外线程上恢复，这个时候没有办法确保锁永远是在单个线程上串行的，所以 Go 语言互斥锁不支持递归锁。

如果不支持递归锁重复锁定就会造成死锁，所以当选择锁的时候一定要慎重，这个锁支不支持递归，语言对这个实现究竟有哪些限制，否则的话很容易死锁。

互斥锁的缺点是它不区分读写操作，比如两个人都去读一份数据的时候，就算不去改变数据，他们也是一个一个来排队，这种并发就变成串行的了。

### 读写锁（RWMutex）

什么情况下才会产生数据竞争？看的情况下肯定没有数据竞争，因为并不改变这个数据，都去读这个数据而不改变这数据的时候肯定不会有竞争效应。

什么情况下有竞争，两个人都去写或者一个读一个写的时候才会产生竞争，所以读写锁是为了改善互斥锁的缺点。

读写锁，你们都去读的时候不用加锁，不加锁意味着不阻塞，所不管多少人去读都没有阻塞的概念，当任意一个人尝试去写的时候，它就会独占锁，所有人都会堵在那，因为它要改变数据，这个时候就会造成阻塞，确保对于所有人来说修改都是同步的。

读写锁是专门针对并发读行为做优化，它在一定程度上能提升这种互斥锁的性能，因为互斥锁对于读并发也变成串行。

读写锁的好处在于当多个并发单元去读的时候，它不会进行阻塞，因为这个时候数据的状态是稳定的不会被修改，多个人去读没有关系，只有发生写的时候才会发生阻塞锁定，所以它对于读大于写的这种场景很容易提升性能，因为它减少了锁的次数。

### 条件锁（Cond）

条件锁是基于锁实现一个条件，我们都可以竞争一把锁，或者说一堆人去竞争一把锁，当其中一个人完成一个操作了以后，它发送一个信号，这个信号有两种激活方式，第一种方式是让阻塞状态的其中一个人激活，第二种方式发送一种广播信号让所有人都激活，这种其实是很常见的。

实际上条件锁是在锁的基础之上实现一个信号通知。利用锁来实现类似消息通知的功能，所以这是锁的另外一种应用。

用锁实现通知，可以让其中一个人激活或者是让多个人同时进行广播激活来实现一种消息，实现一种事件。

### 信号量（Semaphore）

信号量实际上是限制并发的，比如信号量值设置为 3 就意味着有 3 个并发单元可以同时工作，超过的就在那等，其中有一个退出就加进来一个，这个用于控制并发的。

最常见的做法是 Web 请求，可以用信号量控制当前并发速率，即确保当前并发数量是一万个，超过一万个的就堵在那避免数据库或者服务器被拖垮掉。

信号量是用锁来控制并发的数量，超出一个阈值的时候就得等待，其中有任何一个释放了信号量它就可以补进来一个，总共的并发总数限制。

### 自旋锁（SpinLock）

有些时候我们需要做很短的时间锁定，比如说只是做很简单的原子操作，或者一个请求逻辑很快就可以返回，不希望做一次调度把我的时间片让出去，那怎么设计？可以设计 for 循环检查如果 OK 就跳出循环继续执行，如果没有 OK 就继续循环，相当于 for 循环不停的去检查，因为这个时间很短就能返回，这样不需要做控制权的移交，也不需要做上下文的移交。

自旋锁通常用来快速锁定。比如说执行一个锁非常短，没有必要把时间片浪费出去。

自旋锁的好处相对于互斥用于极短时间内的等待，好处是不会让出时间片不会有上下文切换。但是一定要记住，因为它通常是由循环来实现的，所以它会消耗很高的 CPU 资源，如果消耗时间非常长用自旋锁的话可能会导致很严重的问题。对于极短时间内的自旋锁操作，因为它节省了上下文切换，节省了时间片，所以它的效率会很高，选择互斥还是选择自旋完全看你的算法究竟侧重于哪个方面。

### 原子操作（Atomic）

原子操作实际上是用来控制内存操作的事务性，原子操作最常见的做法是用 CAS，用原子操作可以实现 Lock-free，就是所谓的无锁并发。

原子操作是在汇编层面上实现的，或者说是由 CPU 指令来实现的，它的好处是实现类似 lock-free 就是说不用显式的加锁就能保证对多个并发对同一份数据操作的安全性。

### 总结

所以锁比你想象复杂的多，甚至还可以看到远远不止这六种锁，有各种各样的锁，但更多的是在这六种之上进行更多的整合、组合或者是变形来实现在不同的算法需求下进行数据竞争的保护，很多时候我们在数据结构里面发现同时使用多把锁。

任何锁的使用都会影响性能，如果选错的话影响会很大的。

## 第12课：原子操作

### 单核和多核指令是否原子

什么叫原子操作，简单的来讲就是不可分割的操作，高级语言肯定没有办法做到不可分割，简单的变量赋值都不能说不可分割的，因为从汇编上他会翻译成好几条语句呢，很显然高级语言的单条语句很难说是原子操作。

现在的编程模型没有办法去控制底层的东西，我们离汇编越来越远。

### 如何实现原子操作

原子操作实际上是在很极短的生命周期让 CPU 并行失效。所以有些文章中会建议这样一句话，慎重使用原子操作，使用的不好反而降低执行性能，因为多核锁定造成并行变成串行。

第二个问题原子操作只能保证一条汇编指令是原子的，原子操作并不能保证多条汇编指令形成事务，因为你只能锁定单条语句，接下来进行锁定的时候在两条指令中间依然会有其他的核介入进来。

所以原子操作并不能替代互斥，因为互斥可以保证事务，互斥可以完整保证块的逻辑，原子操作只能保证一条汇编指令的完整性。

### CAS（Compare-And-Swap）

其实我们在很多时候利用原子操作 CAS（Compare-And-Swap）这种特性来实现`lock-free`的功能。

CAS 实现方式很简单，比如有一块内存，内存里面保存的数据是 5，CAS 需要三个参数，第一个参数是这个内存的地址，到底要操作谁，第二个参数是指定一个值，这个值称之为 old，就是它会用这个值和内存里的值进行比较，如果这两个值是相等的，它就会用第三个参数换进去，就是说 old 是用来做一次检查，**CAS 完整的意思是先比较然后进行交换**。

### 用原子操作实现自旋锁

Go 语言 Runtime 中自旋锁使用 for 循环实现的，我们也可以用原子操作自己实现自旋锁逻辑。

```
package main

import (
    "runtime"
    "sync"
    "sync/atomic"
)

type SpinLock struct {
    state int64
}

func (s *SpinLock) Lock() {
    for {
        if atomic.CompareAndSwapInt64(&s.state, 0, 1) {
            return
        }

        runtime.Gosched()
    }
}

func (s *SpinLock) Unlock() {
    if !atomic.CompareAndSwapInt64(&s.state, 1, 0) {
        panic("unlock of unlocked spinlock")
    }
}

// go run -race
func main() {
    var wg sync.WaitGroup
    wg.Add(3)

    var spin SpinLock

    x := 0

    inc := func() {
        defer wg.Done()

        spin.Lock()
        defer spin.Unlock()

        for i := 0; i < 10; i++ {
            x++
        }
    }

    for n := 0; n < 3; n++ {
        go inc()
    }

    wg.Wait()
}
```

### 对比通道、互斥锁、原子操作实现并发安全的计数器

原子操作很多时候有很好的性能表现，用通道方式，性能消耗很多，用互斥锁和原子操作性能差异并不大，互斥锁本身就是原子实现。原子操作是单个数据，只是单条指令，最多可以实现数据交换，并不具备多条指令中间的事务，互斥锁加锁和解锁中间过程是事务性的，可以确保处理过程不会被打断。