[TOC]

## 有什么收获

>   当我们学习一门语言时候，语言规范里面肯定不会告诉你很多细节，这些细节甚至和语言规范产生冲突，语言规范会告诉你按照最长的基本类型进行对齐。很多时候代码的异常行为并不是语言规范造成的，有可能是运行时选择的版本有关系。

我们常见的复合结构有很多，从简单的学起，如字符串、数组、字典、结构体。

本课程将带领读者一步一步去探究这些结构的实现原理，了解下面一些问题：

-   为什么所有语言把字符串实现为不可变类型？
-   不同语言对拼接字符串有什么不同实现方式？
-   怎么样优化字符串转换性能？
-   为什么 Go 语言用切片来管理数组，而不是动态数组或数组指针？
-   怎么基于数组实现数据结构栈、队列？
-   字典基本实现方式有哪些？
-   如何改进字典的链表实现性能？
-   字典如何性能调优？清理方法真的有效么？
-   字典有哪些数据竞争问题？
-   结构体内存是怎么布局的？

## 第01课：字符串

### Go 字符串和 C char* 的差异

C 语言中`*char`代表字符串，一个字节数组加个一个结束符。

Go 语言字符串底层也是字节数组，字节数组保存数据但没有结束信息。(它单独会构建一个头信息，头信息开始位置是个指针指向字节数组起始位置，后面用一个长度表达有多长。)

C 语言字符串是连续的内存块。Go 语言里字符串很显然是个`复合结构`，由两块内存组成的，一个是字符串头信息，一个是数据体。

Go 语言判断字符串的长度，`sizeof`处理的是返回类型的长度，很显然所有类型长度都是固定的，大多时候这种复合结构返回类型长度只有头信息。

Go 语言中字符串标准内容是一个指针加上一个长度的标准信息，由两个字段构成，字符串长度是 16 字节。

动态构建的字符串是分配在堆上的，为什么分配在堆上而不分配在栈上？这个字符串是由`strings.Repeat`函数生成的，函数返回局部变量的时候有两种可能，第一种原因是这个函数被内联了直接在当前栈桢分配，如果不能内联返回一个失效栈桢里面的数据是不安全的，只能把这个数据扔到堆上。第二种原因是很多语言对于字符串特殊处理，在大部分语言字符串都是一种很特殊的数据类型。

### 为什么实现为不可变类型

#### 池化共享

任何语言里面的优化基本原则都是基于一定统计的基础。

字符串类型是我们日常工作当中使用频率非常高的数据类型，这种类型的特点是不定长的，对于字符串处理往往非常复杂。

核心问题是需要提高它的处理效率，我们会尽可能的把它缓存起来。

对字符串做池化处理来减少相同字符串在内存当中的副本数量。

#### Map[hashcode]

假如我们自己写个算法比较两个字符串是否相等，你觉得什么方式最快，最简单的做法是直接比较 hashcode，当我们每个字符串生成了以后，这个字符串如果是不可变的情况下，生成完了之后立即计算它的 hashcode，把 hashcode 作为这个字符串对象的一部分，那么接下来只要判断 hashcode 是否相同，如果相同也有可能不一样因为有哈希碰撞问题。

前三个条件可以减少我们低效率操作。这也是让字符串变成不可变类型的原因。

#### 安全性

在有些 DSL 语言有考虑安全性因素，绝大部分编程语言都没有这样考虑。因为这块内存是只读的情况下你对这块内存访问会触发一些安全机制，那么不可写肯定是没有办法修改你的信息的，你没有办法注入非安全的东西，因为很多时候它是支持插件机制的。但这种东西比较少见，只是在一些引擎或者 DSL 里面见过。

### 拼接字符串实现方式

字符串对象既然是只读的不可变的，那么需要修改这个字符串有几种做法？

有种做法把字符串内容复制到字节数组里面去，这样一来面临的问题是在 buffer 时候分配一次内存，然后把它转换为字符串的时候有得分配一次内存，这样一来性能就会很差。

为什么要重新复制内存呢？因为要从不可变类型变成可变类型。不可变类型情况下不能直接修改，不能保证有多少人引用它，在不能保证有多少引用它的情况下修改它的内容的话实际上会带来一些安全风险。最好做法是把它复制一遍然后去生成，这样确保修改不会影响多人的引用。

为什么使用加号方式比用函数方式性能差呢？

以 Go 语言来说，用`join`和`+`没有什么区别。

字符串处理很特殊的地方在不同的语言里有不同的规则。字符串很多时候很多处理都有很特殊的地方。字符串的优化在不同语言里面是不一样的。不要把别的语言里面习惯性经验带到一种新的语言里面。

### 转换性能优化

字符串数据结构先是有底层的字节数组，保存helloworld，然后标准头对象有个指针指向字节数组开始位置，有个长度。这样的结构看上去有点像切片，区别在于没有容量，因为字符串一旦创建之后，它是只读的，在只读的情况下容量含义没有意义了，因为没有扩容的可能。所以字符串与切片具备一定的结构重叠。

![1559609644612](.\pics\1559609644612.png)

那么我们需要字符串类型转换的时候，普通的转换是 string 转换为 []byte 或者 []ruce，[]byte 或者 []ruce 进行修改，修改完再转换为 string。这样做需要做两次内存分配操作，第一次不可变到可变做一次内存分配，然后可变到不可变再做一次内存分配，很显然这种类型转换效果很差。

普通转换把一个字节数组转换为字符串，非安全转换就是我们直接用指针类型来处理头信息来避开复制底层的字节数组，首先确保普通转换和非安全转换方式结果是一样的，很显然两次转换结果是一样的。

### 总结

对于复杂的指针转换获取性能是不是有必要？那估计没有碰到过针对性能带来的巨大压力。有些时候我们为了性能可以抛弃其他的一切，因为在早期我们为了获得性能的话，最极端的做法直接用内联写代码。那不如加机器？增加机器的前提你设计的数据结构或者架构本身支持你加机器，加机器未必提升性能，只是做了分流，但是不能减少单次访问压力。这是两码事，针对面不一样。当 QPS 大的情况下，垃圾回收器往往成为我们的性能瓶颈，所以要减少在堆上内存分配。

## 第02课：数组

### 数组值类型和指针差异

所有的地址空间都可以看成一个字节数组，地址就是数组的序号，数组是所有类型里面最基础的类型，而且它还有个特点是数组的访问效率是高的，因为只需要给出它的下标就可以进行访问某一个元素，给出一个下标的情况下正常情况下编译器会优化成很简单的偏移寻址操作，因为对于寻址操作的效率非常高。

数组是最基础的数据结构，数组和其他数据结构基本差别是什么呢？数组通常是一块完整的内存，基于序号的访问模式。其实整个栈的管理就像一个数组，可以看作都是字节，SP+ 偏移量就是访问内存，看上去所有的数据结构都是由数组的方式构成，因为内存空间可以看成数组。

Go 语言里数组也是一个连续内存，但是数组本身并不代表指针了，可以获得 A[0]、A[1] 的地址，但是 A 本身不再代表A的起始地址。

![1559610124280](.\pics\1559610124280.png)

对于汇编层面来说，传递数据它会复制数据，如果传递的是指针它就复制指针，传递一连串数据它就会复制数据。那么这地方就有个差别，在 C 语言里传递指针你只是复制指针，传递过去以后两边还共享同一份数组，因为两个指针指向同一个数组，我们管这种方式叫做按引用传递。那么在 Go 语言里 A 代表的是整个数据，传递的时候会发生把整个数据复制一遍，它们会各自持有不同的复制体。

![1559610203646](.\pics\1559610203646.png)

我们一定要搞清楚当传递数组过去的时候究竟复制了什么东西？复制的仅仅是指针还是复制的是所有的元素，这地方很大差别的。

### 数组指针和指针数组的差别

数组指针指的是数组的起始位置，通常用一个对象保存这个地址，我们管这个对象叫做数组指针。

把一个变量保存了数组的起始位置，我们管这个东西叫做数组指针。指针数组说白了有个数组，数组里面保存的全是指针，就是说一个数组的元素类型是指针的情况下，我们管这种东西叫指针数组，就等于整数数组整数换成指针而已。

当选择一个结构使用时需要搞清楚到底是什么东西。数组在不同的语言表现方式也不一样，可能是引用传递，就是传递的是指针，也可能是值传递，把整个数组拷贝过去。数组有两种，一种引用整个数组的指针，或者数组里面存的全是指针，这两者是有差别的。

### 切片为什么不是动态数组或数组指针

在 Go 语言里面不支持动态数组的。

Go 语言数组下标必须是个常量，也就是在编译的时候必须要确定的。

对于数组的管理不同语言有不同做法，理论上数组就是静态，因为数组一次性分配好之后通常情况下不会对数组进行扩容。

对数组进行管理，我们通常会提供一个额外的数据结构来管理数组，比如 Go 语言最常见的做法是用称之为切片类型，首先说下什么是切片，切片类型就是一种复合类型，动态分配一段内存，指针指向内存位置，长度信息和容量信息。分配内存的时候指定的长度，可以在运行期确定的。从字面含义上说它引用数组一个片段，比如 A 引用数组位置 1-4 的片段，也可以 B 引用数组位置 3-5 的片段

引用这样片段的话需要什么样的数据结构呢？

![1559610376992](.\pics\1559610376992.png)

第一个肯定需要提供一个指针 pointer，需要知道从哪地方开始，

第二个究竟需要引用多长，片段需要有长度 cap，

额外提供一个当前可操作的范围，len 表示当前可读写操作的范围，cap 表示完整的容量防止越界，完整的切片提供了三个属性，其中可读写的范围表示这里面可能有数据也可能没有数据，如果一开始 len 等于 cap 表示所有地方都可以读写，那么就还原成数组的操作方式，但是如果 len 是动态的话，好处在于只要移动 len 的位置实际上类似于扩容的机制，这就是切片简单的数据结构，用切片模拟动态数组，说白了就是预分配，预分配足够大的内存，这个内存本来就是一个数组，然后提供两个额外的属性对这个数组读写范围的限定以及总容量的限定，而修改 len 来实现类似于扩容的机制。

切片严格意义来说不是动态数组，切片是一个很简单的对数组进行管理的数据结构，但是它本身并不是数组，它通过一个指针引用一个数组，本身显然不是数组，是一个结构体。切片是管理数组中的片段，但切片本身并不是数组，虽然我们操作数据看上去和数组类似，但这仅是一种二级代理机制。所以我们返回切片类型大小的时候，sizeof(type) 实际上是三个字段相加的结果而不是它引用数组的长度。

我们一定要搞清楚每种数据类型本身的数据结构是什么，至于这种类型引用其他的东西。我们可以创建一个切片，然后编译器替自动去分配底层数组，看上去好像这两块内存是一次性完成的，但是从底层布局来说这两个完全是独立的。

### 用 new 或 make 创建引用类型的差别

对分配内存不同做法，Go 语言分为两种方式，一种是 new，一种是 make

new 一个数组`new([8]byte)`计算类型的长度 8bit，分配8字节内存空间，指针返回；

new 一个切片`new([]byte)`计算类型长度 (ptr(8bit)+len(8bit)+cap(8bit))，三个字段组成的24字节内存空间，指针返回。

new 并不会把复合结构完整的去创建，它只计算出当前这个类型究竟需要占用多大的内存空间。很显然用 new 创建切片，这个切片本身是没有办法工作的，其中指针 ptr 没有指向任何底层的数组，因为切片是用来管理数组的，如果被管理的对象不存在的话，那这个管理对象本身没有任何意义。

Go 语言对于一些复合结构使用了一个语法糖，表面上看上去 make 函数，但实际上 make 函数是一个语法糖结构，当我们去`make([]byte,0,8)`时候，首先会创建切片本身头对象 (ptr,len,cap)，然后创建底层数组，数组容量是8个，然后把指针指向开始位置，len 设为0，cap 设为8。很显然 make 操作就包含了几个步骤：

-   第一步创建切片本身；
-   第二步分配底层数组；
-   第三步初始化切片属性。

整个 make 操作是由这三部分组成的，它会翻译成标准的`makeslice`函数。

为什么说 Go 语言用 make 创建引用类型比较坑爹，因为把它称之为引用类型仅仅是由于有一个指针，引用其他的数据结构，这样的结构称之为引用类型。

![1559610598029](.\pics\1559610598029.png)

### 切片和数组的性能差异

切片和数组从语法访问上有些类似，实际上切片是间接的访问底层数组，所以它们之间存在一定的性能差异，这个性能差异不会很大。

数组就是分配一块内存，没有任何管理机制，切片就是两块内存，第一个是切片本身，第二个是切片管理的底层数组

有个问题是返回切片的时候实际上是返回切片本身的内存，要么是切片本身内存的指针，要么是切片本身内存的复制块，意味着底层数组的内存没法返回，必须从栈上逃逸到堆上，因为只返回切片本身，然后栈上栈帧要失效，切片本身可以拷贝到调用栈帧，底层数组必须从栈上分配到堆上。

切片另外很大的问题就是每次操作都需要最少一次的底层数组堆内存分配，也有可能两次，把切片本身和底层数组都分配到堆上去，如果切片本身作为复制品返回的话就是保存在栈上，我们知道堆上分配内存除了本身执行开销以外，还需要加上分配内存的开销垃圾回收的开销，这就是潜在的性能差异。

除了分配内存垃圾回收开销之外，你每次访问需要先读出指针，用指针找到底层数组，然后对底层数组进行读写，起码多了一次寻址过程。而我们对于数组的访问直接是数组的指针加上偏移量就可以操作，没有二次寻址，不要小看寻址差异，如果数据被缓存到 L1-L3 cache 中还好点，如果没有缓存我们必须从主存上去读取，我们知道 CPU 从主存上读数据并没有你想象的那么快。

性能差异很大的原因是因为长度非常的大，如果长度改小点，切片就会被编译器优化，因为对于小切片，一个方法操作并没有超过整个栈帧，那么编译器会尝试把它从切片退化成数组，这样的话属于一种编译器的优化策略。

### 总结

当我们对比两个数据结构的时候，对比方式采样方式需要搞清楚为什么上面有很大的性能差异，而下面的性能差异几乎没有，也没有任何堆分配。这时候需要知道编译器在当中承担什么角色，编译器是否把切片操作优化成普通数组操作，如果优化过后以后那么对于小切片的测试就变得没有意义了，也就是说对于小切片的测试用例来说没有任何意义，因为我们测试的并不是切片，切片并没有体现出切片本身的功能。

学习一个新的语言的时候，如学习数据结构时，测试性能的时候最好的方式是逐级增加测试容量，比如以切片为例，测试范围 10，1000，100000，1000000，测试不同的级别然后看看他们的性能差异有多大，同时要跟踪编译器怎么处理，编译器是否在不同的级别对它不同的优化，它优化的阈值门槛到底有多大，这些关乎到你学习一门语言对数据结构理解多少，因为这些并不能说看 makeslice 源码所知道的。因为看源码的时候只是标准操作，很显然编译器优化时根本没有调用 makeslice 操作，这样的话，除了看源码以外还得尝试看编译器是否调用哪些源码。

大部分语言内置类型比如是由编译器或者运行时支持的内置类型，它都会尝试性能优化操作，因为内置类型对性能要求往往比较苛刻，因为使用频率非常高，那么对性能要求苛刻情况下可以做两件事情，第一尽可能的在栈上操作，第二尽可能使用寄存器。

以后学习新的语言时候一定要知道你测试一种数据结构性能的时候，一定要知道采样多大是合适的，测试多大的范围，编译器在其中是否充当误导我们的作用。不能用简单的小切片和数组对比就说他们的性能差不多，很显然小切片测试没有任何含义，因为根本没有按照标准切片方式来操作。

那么我们现在知道切片和数组的差异，而且也知道切片和数组访问时候一些性能差异，其中最可怕的是在于堆上的内存分配，因为在堆上分配内存的时候就需要垃圾回收进行干预，当我们访问压力比较大的时候，因为使用了切片而没有使用数组，每秒钟可能在堆上产生成千上万个需要回收的对象，这个就是很大的负担。

## 第03课：基于数组实现数据结构

很显然数组带来很大的好处，直接的好处有几点，第一它是一块完整的连续的内存而且只需要一次性分配，第二数组本身访问效率很高，第三我们可以对数组进行复制，因为数组只有一块内存，只要把这一块的内存完整复制就可以了，而其他的很多复合结构可能有多块内存组成的，我们想复制的时候并不容易。

### 栈（Stack）

栈是很典型的先进后出（FILO）数据结构。其实在前面接触很多的栈，调用堆栈本身就是一个栈结构，它是一个内存空间，地址从高位到低位分配，首先高位记录一个位置，比如使用 BP 寄存器保存，另外一个位置用 SP 寄存器来处理当前栈顶的位置。加一个数据即 Push 操作 SP 往上减，弹出一个数据即 Pop 操作 SP 往下增。很显然用一个数组加两个字段来模拟 SP、BP 就可以了。

### 队列（Queue）

队列是很典型的先进先出（FIFO）数据结构。队列如果是一个数组结构，我们从左往右加数据，实际上有两个属性需要注意的，第一个是写 W 的位置，第二个是读 R 的位置。比如可以连续写 3 个格子，写的位置就到位置4，读的位置还是停留在位置1，所以读和写的位置是不一样的。

```
package main

import (
    "errors"
)

type RingQueue struct {
    data []int
    head int
    tail int
}

var (
    ErrQueueFull  = errors.New("queue full")
    ErrQueueEmpty = errors.New("queue empty")
)

func NewRingQueue(cap int) *RingQueue {
    return &RingQueue{
        data: make([]int, cap),
    }
}

func (q *RingQueue) Push(x int) error {
    if (cap(q.data) - (q.tail - q.head)) == 0 {
        return ErrQueueFull
    }

    n := q.tail % cap(q.data)
    q.data[n] = x

    q.tail++
    return nil
}

func (q *RingQueue) Pop() (int, error) {
    if q.tail == q.head {
        return 0, ErrQueueEmpty
    }

    n := q.head % cap(q.data)
    x := q.data[n]

    q.head++
    return x, nil
}
```

一个数组，一个读一个写，写的位置作为头 head，读的位置作为尾 tail。头和尾之间的区域就是有数据的区域。往里面写 Push 的时候，先判断下当前是否有真实的地方有空位，假如无限大小的，tail 减去 head 是有数据的区域，总长度减去有数据的长度就是空位长度，所以`cap(data) - (tail - head)`就是是否有空位，那么 tail 和 head 一直累加和总长度没有关系的，这样的话首先判断是否有空位，如果空位等于零就表示已经满了，直接返回一个错误。如果没有满，把尾部的信息取模操作就是把抽象的环映射到真实的数据结构上面。

### 缓冲区（Pool）

缓冲区的特征是对象复用缓存，假设用一个数组实现缓存，所谓缓存无非就是重复使用这几个格子，对象可能是事先创建好的也可能是事先创建好的连接。

最简单的方式我只需要有一个头，头默认情况下首先把数组串起来，这样首先在第一种状态时候取出可用的状态，当我们第一个取出来以后，头就变成1，这地方记录的是数组的序号。同样的用完放回去以后，Value 先指向头指向的对象，是不是就把新放进来的对象放到了头部，接下来把头指向 Value，是不是每次返回的对象放到头就可以了。

### 链表（Linked List）

用数组实现的前提首先需要预分配足够大的空间，因为在性能优化上面用空间换时间是一种很常见的策略。比如想很多内存分配软件都会用空间换时间，提前去分配足够的空间。

## 第04课：字典

哈希表称之为字典，是我们日常开发中使用频率非常高的类型，例如 Python 中最常见的复合结构就是链表和字典。

首先什么叫哈希函数？其实哈希算法比较宽泛，有很多种不同的实现，它是把一段比较长的数据用一定的算法计算出类似一种摘要信息的东西，这个摘要信息可能是很短的一个字节序列，也可能是个整数。

字典其实有很多种不同的实现。最经典的两种开放地址法和链表法。

#### 开放地址法（Open Hashing）

首先任何一个 Key 通过哈希函数自己定义的算法得出一个结果，这个结果假设是个数字的话，这个数字对于某个固定长度进行取模，得出来的余数肯定是在这个固定长度范围之内。

对于这种开放地址法来说小字典具有很好的操作性能。它没有很复杂的通过二级指针来寻址，它可以把内存进行复用。

开放地址法有个很大的问题在于当超出容量限制的时候需要做扩容，需要对数据进行重新哈希处理。优点是访问性能很好，内存可以复用，缺点是扩容时候需要付出代价，所以它更适合不需要扩容的小字典。

#### 链表法（Closed Hashing）

链表法同样需要提供一个数组，当 K1 取模定位位置，可以直接存，如果 KN 也定位到同样位置，把它作为一个链表放在下面去，理论上只要有重复的就一个一个的往下面加。

链表法有几个问题，优点是数组不需要扩容，增加数据只需要往链表后面追加就行了。缺点是当找到位置的时候，需要对链表进行遍历，我们知道链表的时候性能不是特别好。第二个问题是所有的内存快比较零碎想复用的话并不容易，因为就算复用只能复用数组那块内存，下面所有节点都得 Free 掉，所以这种复用没有多大意义。还有个原因可能某个链表会很长，其它链表可能很短，不平衡，性能上会带来一定的问题，它的好处在于理论上它支持足够多的 KeyValue 数据，不需要做复制处理，因为链表本身每个节点都是独立分配内存的，但是它的访问性能会很差。

### 用数组改进链表法性能

假设有链表法的字典，对于它做性能优化应该怎么做？首先需要调整哈希算法，尽可能让它发布均匀，来实现每个链表的长度相对来说比较短。用数组提高访问性能，每个链表挂的节点可以替换成长度为4的数组，如果超出4个再申请4个，每4个为一组把它构成链表。

那么这地方就会带来几个好处，第一内存块的数据变少了，第二遍历数组比遍历链表快，第三每个内存块长度固定，可缓存起来。用数组改进链表法性能，因为用数组来减少对链表节点，可以把原来多个节点打包成数组改善性能。

有很多种方法来改善性能，前提是得知道字典怎么实现的。通过什么样的方式进行提升呢？第一减少内存分配，第二尽可能复用内存块，第三尽可能让它有缓存亲和性。用空间换时间是很正常的做法。

### 字典的性能调优

#### 预分配

尽可能让基础的数组足够大，因为变大了以后分布会均摊，每个链表本身就会短很多。所以预分配容量的时候很重要。

因为 Go 语言本身也会做扩容处理，因为它会发觉单个链表的节点可能会过长。

提前对字典设置合理的容量有助于改善程序的性能。

#### 键值保存

键值有两种存储方式，第一种所有哈希表上只存指针，那么键值都会保存到堆上去，有多少对键值就会在堆上分配多少对象，这样显然对我们的性能带来很大的影响。

把键值的值直接复制到字典里，用字典来存。这样有助于减少在堆上的对象数量，有助于减少垃圾扫描的时间。

### 字典的数据竞争问题

很多人会问数据结构是不是线程安全的？大部分语言都实现成非线程安全的，为什么不直接做成线程安全？线程安全需要加锁的。

选择一个数据结构是不是线程安全的，前提得知道算法在数据安全范围到底有多大，什么时候开始加锁什么时候开始解锁只有算法知道，数据结构不知道，它没有办法控制这些东西。之所以想找数据安全的是因为你觉得把它从数据算法里分离出去作为独立的存储结构。

Go 语言的特点是所有东西都是并发的，从程序一启动都是并发的，字典是很容易造成并发冲突的，所以 Go 编译器把它当作特等公民对待，只要发现有并发冲突就立马对它进行中断。

字典有非安全问题，比如线程1去写数据可能会引发扩容操作，那么这时候另外线程正在遍历，指针发生变化了处理不了了。

## 第05课：结构体

### 结构体内存布局

当一个结构体包含其它类型的时候，它会把原来的类型展开，所以它的内存布局包含了所有展开的结果，展开的是类型基本的结构。

为什么需要知道内存布局呢？是因为在指针操作的时候要知道操作的是什么东西。

### 名称遮蔽（成员访问优先级）

名称遮蔽是很典型的语法糖。

Go 支持这种结构：定义了三个结构体，`data`里面嵌入了 file 和 log 结构，但是只给了类型没有给字段的名字，这其实就是一个语法糖，真实写法就是用类型做名字：

只不过，字段名字和类型相同，所以就忽略掉了，忽略掉的好处就是我们可以直接用短名去访问被嵌入的名字，看上去有点像短名访问效应。

有个所谓的名称遮蔽问题，如果名字一样，高优先级的会遮蔽掉低优先级的。一般是自己的优先，没有的话找嵌入字段，嵌入字段从数据结构上来说类似于继承的东西，如果两个都有，它没有办法确定哪个，因为 Go 没有真正意义上的继承概念，Python 有多继承的概念，它的规则是从左到右，从下到上。那么你就必须明确指定操作谁。

### 字段对齐（空结构）

内存布局中最重要的内容是字段对齐。

数据对齐有些时候有特定的要求，很多的内存优化策略和 CPU 对数据的访问要求你的地址是偶数。对齐规则比较简单，不管结构体里面有多少个字段，它会找出最长的基本类型，补位凑成最长的长度。数据对齐是平台的要求。

我们在不同的语言里对字段的对齐是不一样的，比如像 C 语言、Go 语言必须手工对齐，手工调整顺序，编译器不会帮你调整顺序，因为这很它的指针和偏移位置有关系。

大部分支持指针操作的语言不会做自动对齐处理的。这个时候比较复杂数据结构的时候而且实例数量非常多的时候需要考虑清楚这种排列是不是最优的。

关于零长度的数据类型是很特殊的东西，当零长度的数据作为成员出现的时候，那么空结构体本身不占用任何空间。当作为数组类型的时候，这个数组其实并不存在，也就是并没有为这个数组分配内存空间。多数语言的空值都是用一个全局变量，也就是所有空值都是指向这个全局变量，所以对这个数组的操作是没有意义的。数组只保留两个基本属性。

空结构体在最后一个字段的时候，我们取 x 的地址会取到别的地方的地址。所以当空结构体在最后一个字段的情况下，编译器会强制的把它当作 1byte 的数据类型来处理。这样虽然不能对 x 进行操作，但是取 x 地址的时候肯定是属于结构体的内存，而不会指向结构体以外的内存。这时对 x 的指针引用可能不会让垃圾回收器对这个东西造成误解。就是避免垃圾回收器造成误解，因为没有这个东西内存指向就越界了。如果空结构体放中间，对它取地址的话无非就指向下一个字段而已，肯定不会越界。

