### 内容大纲

系统模块（内存管理、垃圾回收、Goroutine 调度）：

-   自主实现内存管理
-   内存管理面临的问题
-   Go 基于 tcmalloc 实现的内存分配器工作原理
-   如何释放物理内存
-   垃圾回收常用方式：引用计数、代龄、标记清理
-   垃圾回收何时启动？如何避免内存膨胀，避免影响性能
-   Go 三色标记 + 写屏障模式如何实现并发标记和并发清理
-   控制器和辅助回收的作用
-   Goroutine 调度 G、M、P 模型
-   如何创建 Goroutine
-   如何启动并发任务
-   调度器如何执行
-   M/P 对应关系
-   分段栈的问题是什么
-   连续栈如何实现
-   连续栈回收
-   连续栈扩张问题演示
-   系统监控的用途
-   强制垃圾回收
-   释放物理内存
-   抢占调度
-   处理系统调用
-   I/O 事件

## 第01课：内存管理

### 自主实现内存管理

C 语言中向操作系统申请或者释放内存需要做系统调用的，否则操作系统没有办法收到申请和释放的信号，向操作系统申请，操作系统需要在 mmu 建立映射，建立映射后给内存读写数据，自主管理内存肯定需要减少系统调用带来的系统消耗。

操作系统为什么不管理呢？最主要原因是操作系统根本不知道怎么内存复用，对于操作系统来说，内存复用也就意味着内存不释放。操作系统上运行着各种各样的应用程序，不同语言对于内存使用方式也不一样，选择不同的操作系统，选择不同的编程语言，这里的变化都不好控制。

所以在语言层面上去实现内存分配带来很多好处，第一减少系统调用带来的系统开销，第二自己实现内存复用体系，第三可以和垃圾回收器配合设计得非常精巧，垃圾回收器是回收内存，需要和内存分配器打交道，垃圾回收器不停的进化，内存分配器也要配合它不停的进化。

一句话，操作系统提供的内存分配策略太原始了。

### 内存管理面临的问题

![1559656543759](.\pics\1559656543759.png)

如果不切成大小相等的格子会出现什么状态呢？比如一次切走了1字节，接下来切走3字节，接下来1字节放回来以后，后面空间还在用，除非下次正好用1字节，否则一直用不上，慢慢的切来切去，结果越切越小，最后会形成碎片化，没法管理。Java 语言和 C# 语言内存回收的时候可以把使用的内存全部压缩搬到左边，把右边一大块空出来。C 语言和 Go 语言支持指针，搬的话地址就发生变化，本来大的地址搬到左边去了变成小地址了，所以 C 语言和 Go 语言不能对内存做压缩处理，不能把一个对象随便挪一个位置，除非用户逻辑自己去改变指针。

内存分配最优化的方法是按照 固定大小 的方式分配，这样好处是内存复用会很方便，取内存和放回内存也很方便，还有这种规格大小的很难形成碎片化，因为很容易复用，所有内存都是有固定大小的。

内存复用有两种体系，第一种，规格相同的复用，第二种，把切好的一整块大的内存块还原成自由块，自由块可以用来切成其他的单位。 

通过一种简单的策略知道内存管理简单的方式。无非是向操作系统申请一大块内存，用于减少向操作系统申请次数。申请一大块内存无非需要浪费很大内存空间，这里申请的是 VA 不是 PA，申请 1M 虚拟内存空间，操作系统肯定会及时返回，只有在写数据的时候才会去做 MMU 映射分配物理地址。

### Go 基于 Tcmalloc 实现的内存分配器工作原理

#### Heap 机构的职责

Go 语言 Runtime 具体怎么管理的呢？首先操作系统有很大的内存空间，这个空间称之为堆 Heap

向操作系统申请大量的内存空间，有大有小，称之为自由块，最小的自由块是 1M，Heap 中很多自由块，自由块怎么管理起来呢？自由块的管理方式很简单，对于内存来说它的分类方式两种方式，一个按照字节来分，这种分类方式太琐碎了，数量太多不方便管理，最好的方式按照 页 为单位，内存块有多少页，申请自由块时候说这块内存有多少页，操作系统管理内存的单位是页。

管这些自由块称之为**大对象**，上面规格的自由块称之为**小对象**。实际在程序中小对象的数量是最多的，因为大多数分配内存都是在 1K 以下，起码都是在几页之内的，大对象数量非常的少，没有必要把大对象管理的非常复杂。

对于堆来说，无非就做两种事情，第一种事情，申请自由块，首先从链表中去找，找到大小合适的，找不着的话，从大对象链表去找。

堆是用来管理大块的自由块，大块自由块以页为单位划分到不同的地方。

#### Central 机构的职责

每种门店只提供一种规格的自由块，如果说同一时间内要 1 页的用户请求多，那就排队，1 页和 2 页的申请快速分流，这是很简单的分布式做法。这样锁就分散了，不同规格放到一个地方不管取什么规格内存块都得上锁，我们把这种机构称之为 Central。

#### Cache 机构的职责

用户请求 1 页自由块就去 1 号门店去申请，需要 2 页自由块就去 2 号门店申请。用户请求会关联一个缓存 Cache，这个缓存是以规格大小来保存，为什么要建立缓存呢？因为这个用户请求可以绑定到当前执行线程 Thread 上去。

Central 做一次分流，Cache 一次拿回更多的自由块做了第二次分流，减少同一个 Central 里大量拥挤的行为。

现在的流程是分配内存时候，首先检查 Cache 里有没有，如果有的话直接返回，如果没有的话去检查应该去哪个门店，从门店取回一批，一批是 10 个，Go 语言在初始化时候建立一个静态表，通过这个表查出来到底需要多少个，这个数字基于大量的统计得到的，有些语言根据程序运行期动态调整这个数字。从 Central 里面去取，如果 Central 正好有这样的资源，那就拿回来，如果 Central 没有，它就去 Heap 中去取大块自由块，切回，如果 Heap 没有多余的自由块，去操作系统 OS 申请。

任何时候内存管理都会涉及两个核心问题，第一个快速分配，第二个不能有太多的浪费行为需要适可而止。

Go 语言使用了 ‘三级机构’ 既照顾了快速分配同时又照顾了内存节约，所以它从一开始就是基于并发设计的一种内存分配模型。因为 Go 语言内存分配模型就是基于 tcmalloc。tcmalloc 本身就是 Google 开发的快速内存分配器，它本身就是基于并发设计的，这个原理在这个地方找到相对比较好的平衡，既有很高的性能同时内存消耗不会太夸张。

### 如何释放物理内存

Go 语言怎么做呢？不释放 VA，把 VA 挂在 Heap 上，只是向操作系统提个建议，某一段 VA 暂时不用，可以解除 VA 和 PA 的 mmu 映射，操作系统可能会触发两种行为，第一种行为操作系统物理内存的确不够用有大量的换入换出操作，就解除，第二种操作系统觉得物理内存挺大的，就搁那，但是知道了这段 PA 空间不可用了，在 Heap 中并没有把 VA 释放掉，下次分配正好用到当时解除的 VA，有可能会引发两种行为，第一种是 PA 映射没有解除直接拿过来用，第二种是 PA 被解除掉了会引发操作系统缺页异常，操作系统就会补上这段物理内存，这个过程对用户空间来说是不可见的，这样在用户空间觉得这段内存根本没有释放过，因为用户空间看到的永远是 VA，VA 上某段内存可能存在也可能不存在，它是否存在对用户逻辑来说根本不关心，这地方实际上是操作系统来管理，操作系统通过 mmu 建立映射，这会造成 64 位 VA 地址空间非常的大，只要申请就不释放，下次重复使用，只不过重复使用会补上。现在内存管理在 64 位下简单的多，无非 VA 用就用了，就不释放。Windows 操作系统没有建议解除，只能说全部释放掉。

### 总结

tcmalloc、jemalloc、supper 三种常见内存分配器，很多应用都是基于前两种，比如 Redis 使用前两种替换系统调用的内存分配提升性能。编译 MySQL 时候建议使用前两种内存分配器。

## 第02课：垃圾回收常用方式

### 常用方式：引用计数、代龄、标记清理

#### 引用计数

引用计数实现方式非常简单，每个对象头部都会有一个计数器 ref，这个计数器干嘛用的呢，当引用一个对象的时候计数器加一当取消引用时候减一，当变成 0 的时候立即执行`free`操作内存释放掉，这是很简单的方式。

引用计数的优点实际上是操作非常的快，减一变成 0 操作实际上直接手动调用`free`是一回事。它不需要真正意义上循环扫描，只是单个对象，立即执行`free`操作，其实就是调用减一的操作，实际上直接去判断，它的好处是实现简单、快速，不需要扫描整个进程空间，它定位的是当前单个对象，效率非常高。

#### 引用计数的问题，循环引用垃圾回收

引用计数缺点是循环引用，循环引用很简单，假设两个对象 A 和 B，如果 A 引用了 B，B 数字就加一，B 引用了 A，A 数字加一，这时候释放 A 或者 B 都永远都不会变成 0，相互引用这个数字永远都不会为 0，这种循环引用可能会更复杂，如果有 A、B、C、D 四个，意味着永远释放不了造成内存泄露。

Python 语言提供两套机制，一种机制基于引用计数的默认情况下引用计数在工作，第二种专门引入了 GC，其实它的 GC 严格意义上来讲是专门用来处理这种循环引用的问题。

所以说当一个对象绑定到清理函数或者析构函数的时候，实际上是在第二次回收的时候这个对象才会真正被释放，因为它第一次回收时候它得保证这个对象是活着的，只有这样它在执行清理函数或者析构函数的时候才能保证这两个函数执行不会出错，因为我们没有办法保证这两个函数会不会引用这个对象。很显然当一个对象有析构函数的时候会降低程序整体的性能，当我们写 Python 或者其他语言的时候通常会有人建议尽可能不要使用析构函数，这样的说法其实就是因为对 GC 的影响。

对于大多数这种语言的时候即使垃圾回收器支持循环引用回收，但是如果这两个对象内部包含了析构函数，因为垃圾回收器没法确定它们的析构函数谁先优先执行，所以垃圾回收就会放弃回收它们，从而会引发内存泄露。就算是 Python、Go 语言都会不管这种情况从而引发隐性的内存泄露，很多语言也处理不了这事，所以就算有垃圾回收器，就算垃圾回收器支持循环引用，同样有可能造成内存泄露，就是因为垃圾回收器不知道析构函数是怎么去执行的。

#### 代龄

代龄机制是这样的，对象通常分成三级代龄 0、1、2，当创建新的对象的时候它的代龄为 0，每级代龄都有个预值，当 0 级对象数量超过预值的时候就会启动进程回收，GC 就会扫描所有的 0 级代龄。

通过 0、1、2 三级代龄机制可以有效的把这些长时间活着的对象一点一点的放到 1 级代龄最终放到 2 级代龄里面去，这种长期活着的对象以后不要扫描它，不过它可能在某段时间内死掉但是这种频率相对来说很低，我们用这种方式来减少每次扫描对象数量，这是代龄机制的优点。

有个优点对于 Java、C# 语言来说，可以把 2 级代龄的对象统一搬到一个地方，因为它的生命周期长，把 2 级代龄的对象统一搬到一个地方，1 级代龄统一搬到一个地方，因为生命周期很长，那块内存可以很长时间不动它，扫描只要判断开始和结束位置然后把这里面所有数据全部跳过去，另外因为它们搬到专门的区域那段内存相对稳定同时内存可以被压缩处理不至于大量的碎片化。

#### 标记清理

>    大概知道情况就好。

标记清理最典型的做法是三色标记。

首先当垃圾回收器第一次启动的时候，它把所有的对象都看成白色的，如果这个对象引用了另外一个对象，那么被引用的对象称之为灰色的，把灰色的放入一个队列里去，那么当它第一次扫描完了以后这个无非就是变成两种状态，白色的和灰色的，白色的不属于我们要管的。

接下来扫描所有灰色的对象，灰色对象从队列里拿出来进行扫描，灰色对象被拿出来以后灰色对象本身被标记为黑色的。如果它引用了其他对象那么这个对象重新变成灰色的，它会放入队列里面去，那么黑色对象肯定是活着的不用管了，那么通过这样一级一级的扫描最终因为灰色对象被放入队列里面然后灰色对象拿出来进行扫描，灰色对象本身变成黑色的，最终世界里就变成两种对象一种是活下来黑色的第二种是所有扫描都没有人碰过的白色的，那么黑色的都是活着的白色的都是统统干掉的。

最早的扫描是从哪来的呢，我们称之为从根 Root 对象来的，生命周期可以保证的对象是根对象，线程栈本身就是一个根，线程栈里面可能存了某个对象的指针，那线程栈就会引用那个对象，所以像全局变量、线程栈这些就是根对象。

从它们开始扫描，如果全局变量没有引用任何东西，线程栈也没有引用任何东西，那这些根对象引用的对象肯定可以干掉。全局变量就不说了，线程栈就表示了当前正在引用的那些对象，如果线程栈都没有引用过，那些对象肯定不要了，白色对象可以去掉了。

从根对象开始扫描从一开始大家都是白的，如果根对象有引用，那个对象变成灰色的，灰色对象依次扫描以后就剩下变成两种对象，白色对象和灰色对象，白色对象先放在这，灰色对象放入队列里面去，接下来我们从队列里把灰色对象取出来，看看灰色对象引用了什么对象，灰色对象本身变成黑色的它肯定活下来的，因为它是被别人引用了才会放入队列里面，所以它从灰色变成黑色肯定是活下来的。通过这样把灰色对象一级一级进行递归扫描以后最后这个队列被清空了，剩下来的世界只有两种对象，一种是黑色的肯定被引用过，第二种是没有被引用过的白色对象，黑白两色，黑色活着白色干掉，这就是很典型的三色标记。

### 垃圾回收何时启动？如何避免内存膨胀，避免影响性能？

垃圾回收器不管内存分配操作只管回收操作，甚至具体怎么回收也不管，它只是引发回收告诉内存分配器哪些对象可以被回收，至于内存分配器怎么回收和内存回收器没有关系，它只管什么哪些活着哪些释放就行。

垃圾回收器只是一种辅助装置，它不是核心装置只是辅助回收，它没有办法让程序变的很好，现在只不过不需要用代码时时刻刻去关心释放内存，但是它永远不可能让程序变的更好，一定要记住这一点，因为它不够聪明。

## 第03课：Go 语言垃圾回收实现

### Go 三色标记 + 写屏障模式如何实现并发标记和并发清理

Go 语言早期扫描操作一直处于 STW 状态，大家对这个抱怨非常的深，就是因为扫描操作要冻结用户的内存状态不冻结没法扫描，后来引入了写屏障的技术。

什么叫写屏障，先做一次很短暂的 STW，为什么需要很短暂的呢，它首先要执行一些简单的状态处理，接下来对内存进行扫描，这个时候用户逻辑也可以执行。用户所有新建的对象认为就是黑色的，这次不扫描了下次再说，新建对象不关心了，剩下来处理已经扫描过的对象是不是可能会出问题，已经扫描后的对象可能因为用户逻辑造成对象状态发生改变，所以**对扫描过后的对象使用操作系统写屏障功能用来监控用户逻辑这段内存**。

### 控制器和辅助回收的作用

Go 语言如果发现扫描后回收的速度跟不上分配的速度它依然会把用户逻辑暂停，用户逻辑暂停了以后也就意味着不会有新的对象出现，同时会把用户线程抢过来加入到垃圾回收里面加快垃圾回收的速度。因为并行有四个核，有三个核用户线程执行只有一个核在做垃圾回收，那一个核就有可能跑不过三个核，那把那三个核也抢过来做垃圾回收。这样一来原来的并发还是变成了 STW，还是得把用户线程暂停掉，要不然扫描和回收没完没了了停不下来，因为新分配对象比回收快，所以这种东西叫做辅助回收。

垃圾回收器的算法不是万能的，它也没有办法做到真正意义上的智能，当前的用户逻辑到底适合什么样的算法是很难说的，你需要了解垃圾回收器甚至了解一下它到底怎么工作的，这样来决定选择什么样的垃圾回收算法最合理。

Go 语言在后台用一个循环线程扫描，每2分钟发现不执行就强制回收一次，这样的做法显然比较蠢。后来在 1.5 版本引入一个控制器，控制器有点像 Java 语言动态概念，当这次回收释放比例、或者是这些对象相关一些数据，来对预值动态调整决定下次回收。

任何时候不管用什么语言都有责任减少对象的数量，怎么减少，一尽可能分配到堆上面，二自己创建大数组然后自己重复使用这个数组。这样的话对于垃圾回收来说数组只有一个对象，它有点像块的概念，每个块都需要扫描的，但是我们逻辑中知道怎么处理大数组，不需要它扫描。所以这就是我们一直强调任何时候了解底层都很重要，只有这样程序才能非常好的执行。

任何时候都应该想办法确保你的对象要么分配在栈上，要么尽可能把多个对象合并让它们重复使用一块内存。因为那一块内存相对于垃圾回收器来说只用扫描一次，任何时候对于性能的调优都是重要的，每写一行代码都应该记得这行代码到底会引发多少后台操作。

不要想当然以为这门语言很牛叉有垃圾回收有很高性能内存分配就觉得万事大吉。

## 第04课：Goroutine 调度

### G、M、P 模型

处理器（P），线程（M），并发任务（G）

Goroutine 模型使用的是多对多模型，很多操作系统也抛弃多对多模型而改用一对一模型，因为一对一模型可能对性能上好一点，但是对于海量的并发操作未必是最优秀的。

Go 语言更适合 IO 密集型，对 CPU 密集型来说它对运行时调度不是很合理，它对 CPU 密集计算上不是很好，但是在 IO 密集上做的很好，每种语言都有它适合的地方没有哪种语言适合所有环境，前提是对这门语言了解多少。

### 如何创建 Goroutine

严格来说 Goroutine 不能简单称之为协程，因为 Goroutine 不能从字面层来翻译，它实际上是一套相对来说很复杂的概念，甚至可以抽象成相对完整的虚拟机，我们抛开硬件只说基本架构，Goroutine 本身就是基于并发设计的。

### 如何启动并发任务

![1559658446559](.\pics\1559658446559.png)

这种结构决定了 处理器（P）来控制并发，线程（M）负责具体执行，并发任务（G）来保存任务状态，各自承担自己的角色，共同协作来完成并发任务执行。

### 调度器如何执行

每个 G 任务提供了一个任务所需的函数包括的参数，执行状态的栈，有个空间保存上下文，典型的就是寄存器。

创建一个 G 对象，G 对象被保存到 P 的本地队列或者全局队列中，P 唤醒一个 M，因为 P 创建之后 P 执行当前任务并不会无缘无故的把当前任务停下来，创建 G 对象需要等待时候就在队列里，P 对象它继续执行自己原定的执行序，执行完则需要唤醒 M，这时候唤醒可能有两种，第一个可能是以前创建过现在是休眠状态，第二个可能是没有创建就新建一个，M 就会找有没有空闲的 P，如果有空闲 P 的话，它会把当前创建的 G 对象挪到它身上，接下来这个 M 就会执行调度循环。

### M/P 对应关系

一个 Goroutine 可以在中途实现调度、实现临时保留它的状态然后由另外一个线程去恢复，这是它设计上做的非常巧妙的地方，它借鉴了操作系统保存现场的概念。

这样有什么好处呢？M 本身没有任何状态，每个 M 对应一个系统线程，M 本身不保存任何的状态

G 对象由哪个 M 执行根本不在乎，用 M1 执行切换出去了下次 M2 执行一样的，因为它的状态是自我持有的，跟 M 无关的。这样 M 可以做多路复用，因为 M 本身是无状态的，无状态情况下做复用的话是很正常的，那么所有的状态是 G 保存的，这个设计就是各自做该做的事。