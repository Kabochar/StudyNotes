# 堆，堆排序

## 基础

堆，一种特殊的树。

什么树是堆，必须满足下面两点：

-   堆是一个完全二叉树；二叉树定义：完全二叉树要求，除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。

-   堆中每一个节点的值都必须大于等于（或小雨等于）其子树中每个节点的值。另一种说法：堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。

类别

对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”；对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。

![1553563354774](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553563354774.png)

其中第1个和第2个是大顶堆，第3个是小顶堆，第4个不是堆。

## 如何实现？

完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。因为我们不需要存储左右子节点的指针，单纯地通过数组的下标，就可以找到一个节点的左右子节点和父节点。

![1553563424635](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553563424635.png)

从图中我们可以看到，数组中下标为i的节点的左子节点，就是下标为  i*2  的节点，右子节点就是下标为  i\*2+1 的节点，父节点就是下标为  i / 2  的节点。

### 1，插入元素

堆化：把新插入的元素放到堆的最后，就需要进行调整，让其重新满足堆的特性，这个过程就是堆化。堆化有两种方式，从下往上和从上往下。

从下往上堆化

我们可以让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足刚说的那种大小关系。

![1553563680622](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553563680622.png)

```
public class Heap {
  private int[] a; // 数组，从下标 1 开始存储数据
  private int n;  // 堆可以存储的最大数据个数
  private int count; // 堆中已经存储的数据个数

  public Heap(int capacity) {
    a = new int[capacity + 1];
    n = capacity;
    count = 0;
  }

  public void insert(int data) {
    if (count >= n) return; // 堆满了
    ++count;
    a[count] = data;
    int i = count;
    while (i/2 > 0 && a[i] > a[i/2]) { // 自下往上堆化
      swap(a, i, i/2); // swap() 函数作用：交换下标为 i 和 i/2 的两个元素
      i = i/2;
    }
  }
 }
```

### 2，删除堆顶元素

从堆的定义的第二条中，任何节点的值都大于等于（或小于等于）子树节点的值，我们可以发现，堆顶元素存储的就是堆中 数据的 最大值 MAX 或者 最小值 MIN 。

把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。这就是从上往下的堆化方法。

![1553563824655](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553563824655.png)

```
public void removeMax() {
  if (count == 0) return -1; // 堆中没有数据
  a[1] = a[count];
  --count;
  heapify(a, count, 1);
}

private void heapify(int[] a, int n, int i) { // 自上往下堆化
  while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
  }
}
```

一个包含 n个节点的完全二叉树，树的高度不会超过 log<sub>2</sub>n。堆化的过程是顺着节点所在路径比较交换的，所以堆化的时间复杂度跟树的高度成正比，也就是 O（logn）。插入数据和删除堆顶元素的主要逻辑就是堆化，所以，往堆中插入一个元素和删除堆顶元素的时间复杂度都是O（logn）。

## 如何基于堆实现排序

堆排序的过程大致分解成两个大的步骤，建堆和排序。

### 1，建堆

有两种思路：

1）在堆中插入一个元素。尽管数组中包含n个数据，但是我们可以假设，起初堆中只包含一个数据，就是下标为1的数据。然后，我们调用前面讲的插入操作，将下标从2到n的数据依次插入到堆中。这样我们就将包含n个数据的数组，组织成了堆。（从前往后处理数组数据，并且每个数据插入堆中时，都是从下往上堆化。）

2）从后往前处理数组，并且每个数据都是从上往下堆化。

第二种思路分析：因为叶子节点往下堆化只能自己跟自己比较，所以我们直接从第一个非叶子节点开始，依次堆化就行了。

```
private static void buildHeap(int[] a, int n) {
  for (int i = n/2; i >= 1; --i) {
    heapify(a, n, i);
  }
}

private static void heapify(int[] a, int n, int i) {
  while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
  }
}
```

对下标从号开始到 1的数据进行堆化，下标是 n/2 到 1 的节点是叶子节点，我们不需要堆化。实际上，对于完全二叉树来说，下标从号 n/2+1 到 n 的节点都是叶子节点。

#### 建堆 - 时间复杂度

思路：因为叶子节点不需要堆化，所以需要堆化的节点从倒数第二层开始。每个节点堆化的过程中，需要比较和交换的节点个数，跟这个节点的高度 k成正比。

最后得，复杂度为  O(n)

### 2，排序

建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。我们把它跟最后一个元素交换，那最大元素就放到了下标为n的位置。

当堆顶元素移除之后，我们把下标为 n的元素放到堆顶，然后再通过堆化的方法，将剩下的 n-1 个元素重新构建成堆。堆化完成之后，我们再取堆顶的元素，放到下标是 n-1 的位置，一直重复这个过程，直到最后堆中只剩下标为 1的一个元素，排序工作就完成了。

![1553564462224](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553564462224.png)

```
// n 表示数据的个数，数组 a 中的数据从下标 1 到 n 的位置。
public static void sort(int[] a, int n) {
  buildHeap(a, n);
  int k = n;
  while (k > 1) {
    swap(a, 1, k);
    --k;
    heapify(a, k, 1);
  }
}
```

整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是O（n），排序过程的时间复杂度是O（nlogn），所以，堆排序整体的时间复杂度是O（nlogn）。

堆排序不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。

如果节点的下标是，那左子节点的下标就是 2\*i+1，右子节点的下标就是 2\*i+2 ,父节点的下标就是  i-1 / 2 。

## 场景

在实际开发中，为什么快速排序要比堆排序性能好？

第一点，堆排序数据访问的方式没有快速排序友好。

对于快速排序来说，数据是顺序访问的。而对于堆排序来说，数据是跳着访问的，这样对 CPU 缓存不太友好。

第二点，对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。

## 思考

1，在讲堆排序建堆的时候，我说到，对于完全二叉树来说，下标从身 n/2 + 1 到 n 的都是叶子节点，这个结论是怎么推导出来的呢？

如果下标为n/2 + 1的节点不是叶子节点，即它存在子节点，按照『原理1』，它的左子节点为：2(n/2 + 1) = n + 2，大家明显可以看出，这个数字已经大于n + 1，超出了实现完全二叉树所用数组的大小（数组下标从1开始记录数据，对于n个节点来说，数组大小是n + 1），左子节点都已经超出了数组容量，更何况右子节点。以此类推，很容易得出：下标大于n/2 + 1的节点肯定都是也叶子节点了，故而得出结论：对于完全二叉树来说，下标从n/2 + 1 到 n的节点都是叶子节点

2，我们今天讲了堆的一种经典应用，堆排序。关于堆，你还能想到它的其他应用吗？

1）从大数量级数据中筛选出top n 条数据； 比如：从几十亿条订单日志中筛选出金额靠前的1000条数据

2）在一些场景中，会根据不同优先级来处理网络请求，此时也可以用到优先队列(用堆实现的数据结构)；比如：网络框架Volley就用了Java中PriorityBlockingQueue，当然它是线程安全的

3）可以用堆来实现多路归并，从而实现有序，leetcode上也有相关的一题：Merge K Sorted Lists



# 堆的应用

## 堆的应用一，优先级队列

1，合并有序小文件

假设我们有100个小文件，每个文件的大小是100MB，每个文件中存储的都是有序的字符串。我们希望将这些100个小文件合并成一个有序的大文件。

从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将100个小文件中的数据依次放入到大文件中。我们知道，删除堆顶数据和往堆中插入数据的时间复杂度都是O（logn），n表示堆中的数据个数，这里就是100。

2，高性能定时器

假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如1秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。

但是，这样每过1秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。

可以用优先级队列来解决。我们按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。

定时器就不需要每隔1秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔T。
这个时间间隔T就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在T秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。
当T秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间

## 堆的应用二，求 Top K

求TopK的问题抽象成两类。一类是针对静态数据集合，也就是说数据集合事先确定，不会再变。另一类是针对动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中。

静态资源

可以维护一个大小为K的小顶堆，顺序遍历数组，从数组中取出取数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。

遍历数组需要O（n）的时间复杂度，一次堆化操作需要O（logK）的时间复杂度，所以最坏情况下，n个元素都入堆一次，所以时间复杂度就是O（nlogk）。

动态资源

针对动态数据求得TopK就是实时TopK。

可以一直都维护一个K大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。

如果每次询问前K大数据，我们都基于当前的数据重新计算的话，那时间复杂度就是O（nlogK），n表示当前的数据的大小。

## 堆的应用三，求中位数

借助堆这种数据结构，我们不用排序，就可以非常高效地实现求中位数操作。我们需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。

如果有 n个数据，n 是偶数，我们从小到大排序，那前 n/2 个数据存储在大顶堆中，后 n/2 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果 n是奇数，情况是类似的，大顶堆就存储 n/2 + 1 个数据，小顶堆中就存储 n/2 个数据。

![1553578738145](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553578738145.png)

动态数据情况

如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；如果新加入的数据大于等于小顶堆的堆顶元素，我们就将这个新数据插入到小顶堆。这时我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。

![1553578924199](D:\Documents\笔记本\offer学习复习\堆和堆排序\1553578924199.png)

可以利用两个堆，一个大顶堆、一个小顶堆，实现在动态数据集合中求中位数的操作。插入数据因为需要涉及堆化，所以时间复杂度变成了O（logn），但是求中位数我们只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是O（1）。

如何快速请求接口的 99% 的响应时间？

99百分位数的概念可以类比中位数，如果将一组数据从小到大排列，这个99百分位数就是大于前面99%数据的那个数据。

为了保持大顶堆中的数据占99%，小顶堆中的数据占1%，在每次新插入数据之后，我们都要重新计算，这个时候大顶堆和小顶堆中的数据个数，是否还符合99：1这个比例。如果不符合，我们就将一个堆中的数据移动到另一个堆，直到满足这个比例。

通过这样的方法，每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是O（logn）。每次求99%响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是o（1）。

## 场景

假设现在我们有一个包含10亿个搜索关键词的日志文件，如何快速获取到Top10最热门的搜索关键词呢？

因为用户搜索的关键词，有很多可能都是重复的，所以我们首先要统计每个搜索关键词出现的频率。我们可以通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数。

假设我们选用散列表。我们就顺序扫描这10亿个搜索关键词。

当扫描到某个关键词时，我们去散列表中查询。如果存在，我们就将对应的次数加一；如果不存在，我们就将它插入到散列表，并记录次数为1。以此类推，等遍历完这10亿个搜索关键词之后，散列表中就存储了不重复的搜索关键词以及出现的次数。

然后，我们再根据前面讲的用堆求TopK的方法，建立一个大小为10的小顶堆，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。

以此类推，当遍历完整个散列表中的搜索关键词之后，堆中的搜索关键词就是出现次数最多的Top 10搜索关键词了。

弊端

10亿的关键词还是很多的。我们假设10亿条搜索关键词中不重复的有1亿条，如果每个搜索关键词的平均长度是50个字节，那存储1亿个关键词起码需要5GB的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。

另一种做法

相同数据经过哈希算法得到的哈希值是一样的。我们可以哈希算法的这个特点，将10亿条搜索关键词先通过哈希算法分片到10个文件中。

我们创建10个空文件00，01，02，.…，09。我们遍历这10亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同10取模，得到的结果就是这个搜索关键词应该被分到的文件编号。
对这10亿个关键词分片之后，每个文件都只有1亿的关键词，去除掉重复的，可能就只有1000万个，每个关键词平均50个字节，所以总的大小就是500MB。1GB的内存完全可以放得下。

我们针对每个包含1亿条搜索关键词的文件，利用散列表和堆，分别求出Top10，然后把这个10个Top10放在一块，然后取这100个关键词中，出现次数最多的10个关键词，这就是这10亿数据中的Top10最频繁的搜索关键词了。

## 总结

优先级队列是一种特殊的队列，优先级高的数据先出队，而不再像普通的队列那样，先进先出。实际上，堆就可以看作优先级队列，只是称谓不一样罢了。求TopK问题又可以分为针对静态数据和针对动态数据，只需要利用一个堆，就可以做到非常高效率的查询TopK的数据。求中位数实际上还有很多变形，比如求99百分位数据、90百分位数据等，处理的思路都是一样的，即利用两个堆，一个大顶堆，一个小顶堆，随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。

## 场景

有一个访问量非常大的新闻网站，我们希望将点击量排名Top10的新闻摘要，滚动显示在网站首页banner上，并且每隔1小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？

1，对每篇新闻摘要计算一个hashcode，并建立摘要与hashcode的关联关系，使用map存储，以hashCode为key，新闻摘要为值
2，按每小时一个文件的方式记录下被点击的摘要的hashCode
3，当一个小时结果后，上一个小时的文件被关闭，开始计算上一个小时的点击top10
4，将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中
5，针对每个文件取top10的hashCode，使用Map<hashCode,int>的方式，统计出所有的摘要点击次数，然后再使用小顶堆（大小为10）计算top10,
6，再针对所有分片计算一个总的top10,最后合并的逻辑也是使用小顶堆，计算top10
7，如果仅展示前一个小时的top10,计算结束
8，如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10
9，在展示时，将计算得到的top10的hashcode，转化为新闻摘要显示即可